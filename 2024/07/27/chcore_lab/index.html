<!DOCTYPE html>
<html lang="zh-CN">

<head>
    <meta charset="UTF-8">
<meta name="viewport"
      content="width=device-width, initial-scale=1.0, maximum-scale=1.0, minimum-scale=1.0">
<meta http-equiv="X-UA-Compatible" content="ie=edge">

    <meta name="author" content="修年">





<title>ChCore 实验流程记录 | 修年</title>



    <link rel="icon" href="/favicon.ico">




    <!-- stylesheets list from _config.yml -->
    
    <link rel="stylesheet" href="/css/style.css">
    



    <!-- scripts list from _config.yml -->
    
    <script src="/js/script.js"></script>
    
    <script src="/js/tocbot.min.js"></script>
    



    
    
        
    


      <meta charset="UTF-8">
    <title>live2d-demo</title>
    <script src="https://apps.bdimg.com/libs/jquery/2.1.4/jquery.min.js"></script>
    <!-- Live2DCubismCore -->
    <script src="https://cdn.jsdelivr.net/gh/litstronger/live2d-moc3@master/js/frame/live2dcubismcore.min.js"></script>
    <!-- Include Pixi. -->
    <script src="https://cdnjs.cloudflare.com/ajax/libs/pixi.js/4.6.1/pixi.min.js"></script>
    <!-- Include Cubism Components. -->
    <script src="https://cdn.jsdelivr.net/gh/litstronger/live2d-moc3@master/js/live2dcubismframework.js"></script>
    <script src="https://cdn.jsdelivr.net/gh/litstronger/live2d-moc3@master/js/live2dcubismpixi.js"></script>
    <!-- User's Script -->
    <script src="https://cdn.jsdelivr.net/gh/litstronger/live2d-moc3@master/js/l2d.js"></script>
    <script src="https://cdn.jsdelivr.net/gh/litstronger/live2d-moc3@master/js/main.js"></script>
    <style>
    </style>
<meta name="generator" content="Hexo 5.4.2"></head>

<body>
    <script>
        // this function is used to check current theme before page loaded.
        (() => {
            const currentTheme = window.localStorage && window.localStorage.getItem('theme') || '';
            const isDark = currentTheme === 'dark';
            const pagebody = document.getElementsByTagName('body')[0]
            if (isDark) {
                pagebody.classList.add('dark-theme');
                // mobile
                document.getElementById("mobile-toggle-theme").innerText = "· Dark"
            } else {
                pagebody.classList.remove('dark-theme');
                // mobile
                document.getElementById("mobile-toggle-theme").innerText = "· Light"
            }
        })();
    </script>

    <div class="wrapper">
        <header>
    <nav class="navbar">
        <div class="container">
            <div class="navbar-header header-logo"><a href="/">Xiunian&#39;s Blog</a></div>
            <div class="menu navbar-right">
                
                    <a class="menu-item" href="/about">About</a>
                
                    <a class="menu-item" href="/archives">Posts</a>
                
                    <a class="menu-item" href="/tag">Tags</a>
                
                <input id="switch_default" type="checkbox" class="switch_default">
                <label for="switch_default" class="toggleBtn"></label>
            </div>
        </div>
    </nav>

    
    <nav class="navbar-mobile" id="nav-mobile">
        <div class="container">
            <div class="navbar-header">
                <div>
                    <a href="/">Xiunian&#39;s Blog</a><a id="mobile-toggle-theme">·&nbsp;Light</a>
                </div>
                <div class="menu-toggle" onclick="mobileBtn()">&#9776; Menu</div>
            </div>
            <div class="menu" id="mobile-menu">
                
                    <a class="menu-item" href="/about">About</a>
                
                    <a class="menu-item" href="/archives">Posts</a>
                
                    <a class="menu-item" href="/tag">Tags</a>
                
            </div>
        </div>
    </nav>

</header>
<script>
    var mobileBtn = function f() {
        var toggleMenu = document.getElementsByClassName("menu-toggle")[0];
        var mobileMenu = document.getElementById("mobile-menu");
        if(toggleMenu.classList.contains("active")){
           toggleMenu.classList.remove("active")
            mobileMenu.classList.remove("active")
        }else{
            toggleMenu.classList.add("active")
            mobileMenu.classList.add("active")
        }
    }
</script>
            <div class="main">
                <div class="container">
    
    
        <div class="post-toc" style="right: -4em;">
    <div class="tocbot-list">
    </div>
    <div class="tocbot-list-menu">
        <a class="tocbot-toc-expand" onclick="expand_toc()">Expand all</a>
        <a onclick="go_top()">Back to top</a>
        <a onclick="go_bottom()">Go to bottom</a>
    </div>
</div>

<script>
    var tocbot_timer;
    var DEPTH_MAX = 6; // 为 6 时展开所有
    var tocbot_default_config = {
        tocSelector: '.tocbot-list',
        contentSelector: '.post-content',
        headingSelector: 'h1, h2, h3, h4, h5',
        orderedList: false,
        scrollSmooth: true,
        onClick: extend_click,
    };

    function extend_click() {
        clearTimeout(tocbot_timer);
        tocbot_timer = setTimeout(function() {
            tocbot.refresh(obj_merge(tocbot_default_config, {
                hasInnerContainers: true
            }));
        }, 420); // 这个值是由 tocbot 源码里定义的 scrollSmoothDuration 得来的
    }

    document.ready(function() {
        tocbot.init(obj_merge(tocbot_default_config, {
            collapseDepth: 1
        }));
    });

    function expand_toc() {
        var b = document.querySelector('.tocbot-toc-expand');
        var expanded = b.getAttribute('data-expanded');
        expanded ? b.removeAttribute('data-expanded') : b.setAttribute('data-expanded', true);
        tocbot.refresh(obj_merge(tocbot_default_config, {
            collapseDepth: expanded ? 1 : DEPTH_MAX
        }));
        b.innerText = expanded ? 'Expand all' : 'Collapse all';
    }

    function go_top() {
        window.scrollTo(0, 0);
    }

    function go_bottom() {
        window.scrollTo(0, document.body.scrollHeight);
    }

    function obj_merge(target, source) {
        for (var item in source) {
            if (source.hasOwnProperty(item)) {
                target[item] = source[item];
            }
        }
        return target;
    }
</script>
    

    
    <article class="post-wrap">
        <header class="post-header">
            <h1 class="post-title">ChCore 实验流程记录</h1>
            
                <div class="post-meta">
                    
                        Author: <a itemprop="author" rel="author" href="/">修年</a>
                    

                    
                        <span class="post-time">
                        Date: <a href="#">七月 27, 2024&nbsp;&nbsp;0:19:00</a>
                        </span>
                    
                    
                </div>
            
        </header>

        <div class="post-content">
            <h1 id="Lab0-拆炸弹"><a href="#Lab0-拆炸弹" class="headerlink" title="Lab0: 拆炸弹"></a>Lab0: 拆炸弹</h1><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>感觉做下来还是蛮有意思，做得最难受的是phase4，这加密过程看得我脑壳痛……</p>
<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/qq_24433609/article/details/125991550">关于指令集架构</a></p>
<p>第一次接触ARM架构，还是蛮新奇的。</p>
<ol>
<li><p><code>stp    x29, x30, [sp, #-16]!</code></p>
<p>将寄存器 x29（帧指针, EBP）和 x30（链接寄存器, RA）压入栈中，同时将栈指针sp减去16字节。</p>
<p>[sp, #-16]表示的是sp-16的位置，然后!表示把这个值写回sp寄存器</p>
<p>还有<code>ldp    x29, x30, [sp], #16</code>也是同理。</p>
<p>感觉这两个指令还蛮有意思的，节省了部分开销（可能有点点类似什么超标量的思想（当然还是完全不一样）），而且确实用的地方很多（保护&amp;恢复现场），节省了很多开销。</p>
</li>
<li><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"># adrp 指令获取目标地址的高 12 位，并将其放入 x1 寄存器</span><br><span class="line"># GOT 是一个在程序的可执行文件中或在程序加载到内存时由动态链接器创建的表。</span><br><span class="line"># 它包含了程序中所有被引用的全局变量和外部（其他共享库中的）符号的地址。</span><br><span class="line"># PLT 是一个用于支持动态链接的跳转表，它包含了对外部函数的引用。</span><br><span class="line"># 当程序调用一个外部函数时，它首先跳转到 PLT 中相应的条目。</span><br><span class="line"># 然后，PLT 条目会将控制权传递给动态链接器，链接器解析函数的实际地址，</span><br><span class="line"># 并将其存储在 GOT 中。下一次调用同一个函数时，程序会直接跳转到 GOT 中存储的地址，而不再通过 PLT。</span><br><span class="line">adrp	x1, 4a0000 &lt;.got.plt+0x18&gt;</span><br></pre></td></tr></table></figure></li>
<li><p>x0/w0  x1/w1</p>
</li>
<li><p>需要下载<code>aarch64-linux-gnu-objdump</code>，貌似不能用通用的<code>objdump</code>（加了-m选项也还是不行）。</p>
</li>
</ol>
<h2 id="具体内容"><a href="#具体内容" class="headerlink" title="具体内容"></a>具体内容</h2><p>通关！</p>
<p><img src="/2024/07/27/chcore_lab/image-20240727180820446.png" alt="image-20240727180820446"></p>
<h3 id="phase0"><a href="#phase0" class="headerlink" title="phase0"></a>phase0</h3><p>只需要控制w1和w0的值相等就即可。用GDB调试一下就行。</p>
<h3 id="phase1"><a href="#phase1" class="headerlink" title="phase1"></a>phase1</h3><p>这次是字符串</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">  40076c:	f9402c21 	ldr	x1, [x1, #88]</span><br><span class="line">  400770:	94008504 	bl	421b80 &lt;strcmp&gt;</span><br><span class="line"># 就是说如果w0不为零就爆炸，也就是说输入的字符串要跟x1所在字符串一样</span><br><span class="line">  400774:	35000060 	cbnz	w0, 400780 &lt;phase_1+0x20&gt;</span><br></pre></td></tr></table></figure>

<p><img src="/2024/07/27/chcore_lab/image-20240726233511926.png" alt="image-20240726233511926"></p>
<h3 id="phase2"><a href="#phase2" class="headerlink" title="phase2"></a>phase2</h3><p>需要了解其栈结构，并且看懂它这个循环代码。迭代计算斐波那契数列。</p>
<h3 id="phase3"><a href="#phase3" class="headerlink" title="phase3"></a>phase3</h3><p>phase_3是一个类似分支条件的结构。</p>
<p>第一个参数为3(w1)，第二个参数x需满足 : (x^(x&gt;&gt;3)) &amp; 0x07（取后三位） == 3(w1)。3 3即可满足要求。</p>
<p>第一个参数为6，这段计算太复杂了我有点没看懂，略……不过看其他俩的套路应该是6 6。</p>
<p>第一个参数为2(w1)，第二个参数x需满足 : (x &amp; 0x7) == 2。2 2即可满足要求。</p>
<h3 id="phase4"><a href="#phase4" class="headerlink" title="phase4"></a>phase4</h3><p>一个简单的对输入字符串加密的程序，给定一个经过两次编码变换的结果字符串，要求逆向求出其原始字符串。</p>
<p>helloworlc-&gt;isggstsvke</p>
<ol>
<li><p>观察encrypt_method2可知其大概是一个字母变换的函数，并且要求输入只能是仅含小写字母（不能含a）的序列</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">4009b4:	51018400 	sub	w0, w0, #0x61</span><br><span class="line">4009bc:	7100641f 	cmp	w0, #0x19</span><br></pre></td></tr></table></figure></li>
<li><p>在phase_4中可打印出目标字符串</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># 输入字符串和某静态字符串应该相等</span><br><span class="line">  400a24:	94008457 	bl	421b80 &lt;strcmp&gt;</span><br></pre></td></tr></table></figure>

<p>打印x0和x1即可得到两个字符串的地址，访存可知目标字符串为isggstsvke。</p>
</li>
<li><p>测试调试几遍可知，大概思路是encrypt_method1负责乱序，encrypt_method2负责字母映射编码</p>
</li>
<li><p>观察encrypt_method2可获取字母映射表的静态存储地址，打印获得映射表，对2中的字符串反编码，得到原始字母序列</p>
<p>字母映射表在地址0x400998处，查询[x0-97]附近值即可。</p>
<p><img src="/2024/07/27/chcore_lab/image-20240727024252825.png" alt="image-20240727024252825"></p>
</li>
<li><p>encrypt_method1的变换我没太看懂（也有点懒研究哈哈哈），我最终从字母里感觉有点像helloworld（再加上还是10个字哈哈哈）猜出来的。</p>
</li>
</ol>
<h3 id="phase5"><a href="#phase5" class="headerlink" title="phase5"></a>phase5</h3><p>最后一个phase是一个递归函数，使用x0和x1交替传递返回值和参数。</p>
<p>观察可知phase_5要求func_5这个递归函数最终返回的是3。查看func_5的逻辑，可以将其转化为类似的伪代码：</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> (x1 == <span class="number">0</span>)  <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line"><span class="keyword">if</span> (x0 == *x1)  explode();</span><br><span class="line"><span class="keyword">if</span> (*x1 &lt;= x0) <span class="keyword">goto</span> END;</span><br><span class="line">x1 = *(x1 + <span class="number">8</span>);</span><br><span class="line">x0 = func(x0, x1);</span><br><span class="line">x0 *= <span class="number">2</span>;</span><br><span class="line"><span class="keyword">return</span>;</span><br><span class="line">END:</span><br><span class="line">x1 = *(x1 + <span class="number">16</span>)</span><br><span class="line">x0 = func(x0, x1);</span><br><span class="line">x0 = x0 * <span class="number">2</span> + <span class="number">1</span></span><br><span class="line"><span class="keyword">return</span></span><br><span class="line">    </span><br><span class="line"><span class="comment">// 更高级语言一点</span></span><br><span class="line"><span class="type">int</span> func (<span class="type">int</span> a, <span class="type">int</span> *b) &#123;</span><br><span class="line">  <span class="keyword">if</span> (*b == <span class="number">0</span>)  <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line">  <span class="keyword">if</span> (a == *b)  GG.</span><br><span class="line">  <span class="keyword">if</span> (a &lt; *b) &#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">2</span> * func(a, (b + <span class="number">8</span>));</span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">2</span> * func(a, (b + <span class="number">16</span>)) + <span class="number">1</span>;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>其中x1指向一个数组。</p>
<p>所以我们可以看出来，他大概就是一直将输入a和数组b中的元素进行对比。如果a大于等于该元素，那么就移动一个步长，继续比较，并且返回一个偶数；否则，移动两个步长，返回一个奇数。</p>
<p>由于phase_5中要求我们得到3，故而可能的结果序列只能是 3 1 0，也即前两次递归都进入分支2（输入必须小于），其他次递归都进入分支1，最后一次递归是由<code>*b == 0</code>终止。</p>
<p>于是我们可以看看x1所指向的数组的内容：</p>
<p><img src="/2024/07/27/chcore_lab/image-20240727180732827.png" alt="image-20240727180732827"></p>
<p>[49] 0 [20] 0 [92] 0 20 0 [3] 0 [37] 0 92 0 [55] 0 [94] 0 3 0 0 0 0 0 37等等等</p>
<p>当输入为93的时候轨迹如上，很完美实现它的要求。</p>
<h1 id="Lab1-内核启动"><a href="#Lab1-内核启动" class="headerlink" title="Lab1: 内核启动"></a>Lab1: 内核启动</h1><blockquote>
<p><a target="_blank" rel="noopener" href="https://static.docs.arm.com/100076/0100/arm_instruction_set_reference_guide_100076_0100_00_en.pdf">ARM手册</a></p>
</blockquote>
<p>感觉最大的收获还是亲身体验了一把启动流程，以前只简单看过XV6的C代码和听过课的讲解，这还是第一次直接钻到汇编底下看。。。感觉OS作为软硬件接口，非常好的一个地方就是他不会太hw，有需要就设一下寄存器让硬件自己猜就行了，这点我很喜欢哈哈。</p>
<p><img src="/2024/07/27/chcore_lab/image-20240728215416372.png" alt="image-20240728215416372"></p>
<h2 id="实验内容"><a href="#实验内容" class="headerlink" title="实验内容"></a>实验内容</h2><blockquote>
<p>之前也简单探究过OS启动的流程，这里放上站内文章链接：</p>
<p><a href="/2023/07/26/kernel_boot">kernel boot</a>【BIOS-&gt;GRUB】</p>
<p><a href="https://xiunianjun.github.io/2023/01/10/xv6$chap2/#Code-starting-xv6-and-the-first-process:~:text=%E4%BA%8Epcb%E8%A1%A8%E3%80%82-,Code%3A%20starting%20xv6%20and%20the%20first%20process,-%E7%9C%8B%E5%AE%8C%E4%B8%80%E9%81%8D%E8%AF%B4">Code: starting xv6 and the first process</a>【GRUB将操作权给到OS之后的启动】</p>
</blockquote>
<p>感觉此处的bootloader就是类似于grub的结构，负责切换异常级别、初始化串口和内存映射并且最终跳转到真.OS。</p>
<p>总体流程及关键函数大概是：</p>
<ol>
<li><p>内核镜像构建</p>
<p>本实验代码包含了基础的ChCore 微内核操作系统，除了练习题相关的源码以外，其余部分通过二进制格式提供，最终编译构建成为一个ELF格式的内核映像文件。</p>
<p>可以使用readelf工具或者什么objdump来查看<code>kernel.img</code>。</p>
<p>通过<code>kernel/arch/aarch64/boot/linker.tpl.ld</code>精细设计了.init等段的大小和位置。</p>
<p><img src="/2024/07/27/chcore_lab/image-20240729003451663.png" alt="image-20240729003451663"></p>
<p>在cmake文件可看到bootloader大概包含这些东西：</p>
<figure class="highlight cmake"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">list</span>(</span><br><span class="line">    APPEND</span><br><span class="line">    _init_sources</span><br><span class="line">    init/start.S</span><br><span class="line">    init/mmu.c</span><br><span class="line">    init/tools.S</span><br><span class="line">    init/init_c.c</span><br><span class="line">    peripherals/uart.c)</span><br><span class="line"></span><br><span class="line">chcore_target_sources_out_objects(<span class="variable">$&#123;kernel_target&#125;</span> PRIVATE init_objects</span><br><span class="line">                                  <span class="variable">$&#123;_init_sources&#125;</span>)</span><br></pre></td></tr></table></figure>

<p>然后具体通过ld配置文件控制每个段的具体位置和装载位置。</p>
</li>
<li><p><code>_start</code>（在<code>start.S</code>中）</p>
<p>primary CPU执行主要的初始化流程，其他CPU等待至完成。</p>
</li>
<li><p><code>arm64_elX_to_el1</code>（在<code>tools.S</code>中）</p>
<p>负责特权级别的切换，启动时为EL3-&gt;EL1。</p>
<blockquote>
<p>AArch64 架构中，特权级被称为异常级别（Exception Level，EL），四个异常级别分别为 EL0、EL1、EL2、EL3，其中 EL3 为最高异常级别，常用于安全监控器（Secure Monitor），EL2 其次，常用于虚拟机监控器（Hypervisor），EL1 是内核常用的异常级别，也就是通常所说的内核态，EL0 是最低异常级别，也就是通常所说的用户态。</p>
</blockquote>
<p>切换特权级要做的不多，只需修改相关寄存器即可。对于aarch64来说，它假定的特权级切换流程如下：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">假设处理器当前在EL1（异常级别1）运行，并且发生了一个异常导致处理器切换到EL3（异常级别3）来处理该异常。</span><br><span class="line"></span><br><span class="line">处理器在进入EL3时：</span><br><span class="line">1. 保存当前状态到SPSR_EL3</span><br><span class="line">2. 保存返回地址到ELR_EL3</span><br><span class="line"></span><br><span class="line">在处理完异常后，执行`ERET`指令，处理器会：</span><br><span class="line">1. 从SPSR_EL3获取原有处理器状态。</span><br><span class="line">2. 从ELR_EL3获取原有返回地址。</span><br><span class="line">3. 切换目标特权级别（从SPSR获取），跳转回原先的程序执行。</span><br></pre></td></tr></table></figure>

<p>所以在这里，我们相当于需要手动填写一下EL3相关寄存器就行。</p>
<p>原所有代码感觉还是非常优美地封装了(EL3、EL2、EL1)-&gt;EL1这几种case的。</p>
<p>如果是EL2切回EL1，看起来其切换逻辑大概是，还是经典eret，只不过把ELR_EL2换成指向一个ret指令的label。也即先进行一个eret，再进行一个ret，那就是类似emm，应该是叫VM Exit之类的。</p>
<p>如果是EL1切回EL1，那就只需要进行一个普通的ret就行，那就是函数调用。</p>
</li>
<li><p><code>_start</code>（在<code>start.S</code>中）</p>
<p>准备好C语言环境需要用的栈，然后去执行C代码。</p>
<blockquote>
<p>思考题：为什么要在进入 C 函数之前设置启动栈。如果不设置，会发生什么？</p>
<p>调试可知，不设置sp=0，会覆盖未知地址</p>
</blockquote>
</li>
<li><p><code>init_c</code>（在<code>init_c.c</code>中）</p>
<ol>
<li><p>clear bss</p>
<blockquote>
<p>思考题 5：在实验 1 中，其实不调用 <code>clear_bss</code> 也不影响内核的执行，请思考不清理 <code>.bss</code> 段在之后的何种情况下会导致内核无法工作。</p>
<p>感觉多核（此时别的CPU会一直spin），或者说直接用到这些未初始化的全局变量的时候</p>
</blockquote>
</li>
<li><p>初始化串口</p>
<p>我之前也写过简单的串口，aarch64也是属于外设和内存统一编址。</p>
</li>
<li><p>内存映射相关</p>
<ol>
<li><p><code>init_kernel_pt</code>设置好页表</p>
<p>首先先记一下chcore的内存管理图方便未来查阅吧。</p>
<p><img src="/2024/07/27/chcore_lab/lab1-trans.svg" alt="lab1-trans"></p>
<blockquote>
<p>“Output address”在这里即物理地址，一些地方称为物理页帧号（Page Frame Number，PFN）</p>
</blockquote>
<p><img src="/2024/07/27/chcore_lab/lab1-pte-1.png" alt="lab1-pte-1"></p>
<p><img src="/2024/07/27/chcore_lab/lab1-pte-2.png" alt="lab1-pte-2"></p>
<blockquote>
<p>操作系统内核通常运行在虚拟内存的高地址。在内核运行时，访问内核代码和数据，对任意物理内存和外设内存（MMIO）进行读写，都使用高地址。</p>
<p>因此，在内核启动时，首先需要对<strong>内核自身、其余可用物理内存和外设内存</strong>进行虚拟地址映射，最简单的映射方式是一对一的映射，即将虚拟地址 <code>0xffff_0000_0000_0000 + addr</code> 映射到 <code>addr</code>。需要注意的是，在 ChCore 实验中我们使用了 <code>0xffff_ff00_0000_0000</code> 作为内核虚拟地址的开始（注意开头 <code>f</code> 数量的区别），不过这不影响我们对知识点的理解。</p>
</blockquote>
<table>
<thead>
<tr>
<th>物理地址范围</th>
<th>对应设备</th>
<th>映射粒度</th>
<th>类别</th>
</tr>
</thead>
<tbody><tr>
<td><code>0x00000000</code>~`0x3f000000`</td>
<td>物理内存（SDRAM）</td>
<td>2MB</td>
<td>normal</td>
</tr>
<tr>
<td><code>0x3f000000</code>~`0x40000000`</td>
<td>共享外设内存</td>
<td>2MB</td>
<td>device</td>
</tr>
<tr>
<td><code>0x40000000</code>~`0xffffffff`</td>
<td>本地（每个 CPU 核独立）外设内存</td>
<td>1GB</td>
<td>device</td>
</tr>
</tbody></table>
<blockquote>
<p>我们需要在 <code>init_kernel_pt</code> 为内核配置从 <code>0x00000000</code> 到 <code>0x80000000</code>（<code>0x40000000</code> 后的 1G，ChCore 只需使用这部分地址中的本地外设）的映射，其中 <code>0x00000000</code> 到 <code>0x3f000000</code> 映射为 normal memory，<code>0x3f000000</code> 到 <code>0x80000000</code>映射为 device memory，其中 <code>0x00000000</code> 到 <code>0x40000000</code> 以 2MB 块粒度映射，<code>0x40000000</code> 到 <code>0x80000000</code> 以 1GB 块粒度映射。</p>
</blockquote>
<p>在kernel中看它意思，我们貌似只采取到L2，故而最终也是以2MB块的形式访存。</p>
<p>至于为什么本地外设要整个1GB，emmm，说实在的我真不大清楚，这点留到写完实验后再来思考吧。TODO。我感觉可能还是因为，比如说<code>0x40000000</code> 到 <code>0x80000000</code> 这部分一般就不怎么用，然后再后面就属于用户空间内核管不着了（）</p>
<p>然后这边的映射关系也是很线性，相当于直接把低地址这些摁抬上高地址了，简单粗暴。</p>
</li>
<li><p><code>el1_mmu_activate</code>开启MMU</p>
<p>开启MMU映射其实就是把页表地址填入相关寄存器，然后再设置一下控制寄存器就OK了。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">/* Write ttbr with phys addr of the translation table */</span><br><span class="line">adrp    x8, boot_ttbr0_l0</span><br><span class="line">msr     ttbr0_el1, x8</span><br><span class="line">adrp    x8, boot_ttbr1_l0</span><br><span class="line">msr     ttbr1_el1, x8</span><br><span class="line">isb</span><br><span class="line"></span><br><span class="line">mrs     x8, sctlr_el1</span><br><span class="line">/* Enable MMU */</span><br><span class="line">orr     x8, x8, #SCTLR_EL1_M</span><br></pre></td></tr></table></figure>

<blockquote>
<p>思考题 11：请思考在 <code>init_kernel_pt</code> 函数中为什么还要为低地址配置页表，并尝试验证自己的解释。</p>
<p>因为在开启完MMU、跳转到高地址（还得再过几步）之前，还需要使用原有的栈和驱动内存。</p>
<p>如果我们未初始化的话，开启MMU的时候会是0：</p>
<p><img src="/2024/07/27/chcore_lab/image-20240728220231646.png" alt="image-20240728220231646"></p>
<p>然后sp保存的又是低地址，所以需要前往低地址页表寄存器，导致之后栈访存指令GG：</p>
<p>ldp     x29, x30, [sp], #16</p>
<p>驱动内存也应该是同理可得，大概。</p>
</blockquote>
</li>
</ol>
</li>
<li><p><code>start_kernel</code></p>
<p>可以看到看起来也是先构造了一个高地址的sp：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">ffffff000008e000 &lt;start_kernel&gt;:</span><br><span class="line"># 造出来之后sp=ffffff000008f060，貌似指向一段el1_vector区域，不知道在干嘛，难道是异常向量表？总之TODO</span><br><span class="line">ffffff000008e000:	58000302 	ldr	x2, ffffff000008e060 &lt;secondary_cpu_boot+0x38&gt;</span><br><span class="line">ffffff000008e004:	91400442 	add	x2, x2, #0x1, lsl #12</span><br><span class="line">ffffff000008e008:	9100005f 	mov	sp, x2</span><br><span class="line">ffffff000009470c:	a9bf07e0 	stp	x0, x1, [sp, #-16]!</span><br><span class="line">ffffff0000094710:	f0002aa2 	adrp	x2, ffffff00005eb000 &lt;empty_page&gt;</span><br><span class="line">ffffff0000094714:	d5182002 	msr	ttbr0_el1, x2</span><br></pre></td></tr></table></figure>

<p>然后将高地址的新页表地址覆盖<code>ttbr0_el1</code>，作用应该是清零低地址页表，这样一来之后访问地址就相当于非法访问内存越界了，于是乎就开启了全高地址映射。</p>
<p>然后就跳到main那边了。</p>
</li>
</ol>
</li>
</ol>
<h2 id="小品环节"><a href="#小品环节" class="headerlink" title="小品环节"></a>小品环节</h2><h3 id="环境配置"><a href="#环境配置" class="headerlink" title="环境配置"></a>环境配置</h3><p>这里记录一下我一个很幽默的无脑行为，最后发现是一场乌龙，给大伙笑一笑算了哈哈哈。</p>
<p>具体是这样，我在做实验之前先开始配环境，然后实验内容做啥都还一眼没看。再加上以前做lab的经历，还有看指导书的意思【注：貌似是看了不对版本的指导书】，我就误以为配完环境直接<code>make qemu</code>就可以简单跑起来（事实上还需要先写完lab1），然后看到欢迎信息了。</p>
<p>然后，我这docker pull又一直失败，我不得不尝试多种方法来曲线救国，但总归还是不大安心，所以后面我压根没想到这可能是代码问题，一直觉得是环境问题，最后折腾了两个小时才发现原来是还得写Lab1才能启动……</p>
<p>我这很容易不知不觉就陷进细节开始钻牛角尖的毛病是时候该改改了。不过这长达两个小时的折腾过程也让我学了挺多工具（包括我也是第一次使用docker、第一次更细致地了解qemu的用法），所以这里暂且先记录下来。</p>
<h4 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h4><p>本次环境配置的大概思路是这样的。docker仅仅是负责提供一个交叉编译环境，最后输出一个<code>kernel.img</code>文件。然后我们用qemu启动整个ChCore。qemu命令如下：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">qemu-system-aarch64 -machine raspi3 -nographic -serial mon:stdio -m size=1G -kernel ./build/kernel.img</span><br></pre></td></tr></table></figure>

<p>前置环节：根据<a target="_blank" rel="noopener" href="https://ipads.se.sjtu.edu.cn/courses/os/">指导书</a>配置。</p>
<h4 id="网络问题探究"><a href="#网络问题探究" class="headerlink" title="网络问题探究"></a>网络问题探究</h4><p>首先尝试发现docker硬是pull不下来，<a target="_blank" rel="noopener" href="https://cr.console.aliyun.com/cn-hangzhou/instances/mirrors">配置阿里云镜像</a>无果，<a target="_blank" rel="noopener" href="https://www.jianshu.com/p/6b148fdec361">配置pull时代理（采用了方法1）</a>无果。</p>
<p>不大清楚为什么……</p>
<h4 id="直接编译"><a href="#直接编译" class="headerlink" title="直接编译"></a>直接编译</h4><p>不得已，选择直接用gcc-aarch64编译。寻找一番可知修改<code>chbuild</code>脚本中的选项即可：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="title">_main</span></span>() &#123;</span><br><span class="line">    run_in_docker=<span class="literal">true</span>	<span class="comment"># 改为 false</span></span><br></pre></td></tr></table></figure>

<p>编译成功通过，然而，<code>make qemu</code>不知道为什么卡住，但Ctrl+AX依然可以响应：</p>
<p><img src="/2024/07/27/chcore_lab/image-20240728143318801.png" alt="image-20240728143318801"></p>
<p>联想到当初做XV6也有类似问题，是因为qemu版本不匹配。我一开始qemu是6.2.0，但更换qemu版本（试了5.1.0、3.1.0）依然还是不行，百思不得其解，想着会不会是确实编译器版本也有影响，所以准备另寻他路。</p>
<h4 id="自建容器"><a href="#自建容器" class="headerlink" title="自建容器"></a>自建容器</h4><p>上个方法不大行得通，所以我换了个思路。docker pull不下来，我就开始自己创建一个新容器。</p>
<p>在github搜索，找到了<a target="_blank" rel="noopener" href="https://github.com/WilliamX1/ChCore/blob/bcc523dc1597feab014a41482b27fca329b1e20e/scripts/build/Dockerfile#L4">往年的ChCore-Lab</a>，提供了Dockerfile。然后可能因为docker在普通用户模式下运行，所以我需要给容器加一个跟当前用户id一致的用户。我这边是1000：</p>
<figure class="highlight dockerfile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 在该文件基础上增加</span></span><br><span class="line"><span class="keyword">RUN</span><span class="language-bash"> groupadd -g 1000 group123</span></span><br><span class="line"><span class="keyword">RUN</span><span class="language-bash"> useradd -u 1000 -g 1000 user123</span></span><br></pre></td></tr></table></figure>

<p>总之成功把容器整出来了。根据其修改<code>chbuild</code>脚本容器名即可。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">$ docker image <span class="built_in">ls</span></span><br><span class="line">REPOSITORY       TAG       IMAGE ID       CREATED       SIZE</span><br><span class="line">chcore_builder   latest    38d06c761f8c   2 hours ago   716MB</span><br><span class="line"><span class="comment"># in chbuild</span></span><br><span class="line">docker run -i <span class="variable">$use_tty</span> --<span class="built_in">rm</span> \</span><br><span class="line">    -u $(<span class="built_in">id</span> -u <span class="variable">$&#123;USER&#125;</span>):$(<span class="built_in">id</span> -g <span class="variable">$&#123;USER&#125;</span>) \</span><br><span class="line">    -v $(<span class="built_in">pwd</span>):$(<span class="built_in">pwd</span>) -w $(<span class="built_in">pwd</span>) \</span><br><span class="line">    --security-opt=seccomp:unconfined \</span><br><span class="line">    chcore_builder \</span><br><span class="line">    <span class="variable">$self</span> <span class="variable">$@</span></span><br></pre></td></tr></table></figure>

<p>此处还有一个小插曲，<code>make build</code>之后还爆了奇奇怪怪的错。还好很快发现是我在尝试方法2的时候忘了clean了，不然又得排查老半天。。。</p>
<p>然后总之，也是成功编译出了kernel img，然而依然<code>make qemu</code>卡住。。。。。</p>
<p>我感觉应该不是qemu版本问题，估计是编译出的kernel img有啥问题，所以我准备具体看看qemu究竟卡在哪了。</p>
<h4 id="探究qemu"><a href="#探究qemu" class="headerlink" title="探究qemu"></a>探究qemu</h4><p><code>qemu_wrapper.sh</code>的逻辑还蛮经典。</p>
<p>我加了句打印get到了qemu具体的运行命令，然后给它加了个<code>-d</code>选项用来调试。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="variable">$qemu</span> --version</span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;<span class="variable">$&#123;qemu&#125;</span> <span class="variable">$&#123;qemu_options&#125;</span>&quot;</span></span><br><span class="line">qemu-system-aarch64 -machine raspi3 -nographic -serial mon:stdio -m size=1G -kernel ./build/kernel.img -d all</span><br></pre></td></tr></table></figure>

<p>【其实这里可以用GDB的。我那时因为不知道具体到底什么问题，所以用了-d参数。】</p>
<p>然后我发现有几个CPU（Trace编号不同）都卡在了<code>PC=000000000008000c</code>。我感觉这长得很像一个很特殊的数字，于是查到了往年sjtu学生的<a target="_blank" rel="noopener" href="https://ipads.se.sjtu.edu.cn/ospi/discussion/u/LYJ#:~:text=8000c%3A%2094000000%20bl%208000c%20%3Csecondary_hang%3E">讨论</a>，以及<a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/411538727#:~:text=intorduce%20multi%2Dprocessors%20*/-,secondary_hang%3A,-bl%20secondary_hang">这个</a>，得知这是一段内核启动常见操作，【当然现在貌似没有这个函数了】也即有一个primary CPU负责初始化流程，其他CPU就等待，而这正是等待的逻辑。</p>
<p>从帖子中我了解到主CPU存储在X8寄存器，所以我就去重点关注<code>X8=0</code>的Trace，最终发现主CPU在执行完<code>PC=0000000000088080</code>的代码之后不知道怎么回事可能就出错了，之后PC的值变成了200，并且qemu提示<code>Taking exception 1 [Undefined Instruction]</code>。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Trace 0: 0x7f68840012c0 [0000000000000000/0000000000088080/0xb0000000] arm64_elX_to_el1</span><br><span class="line"> PC=0000000000088080 X00=0000000000000000 X01=0000000000000000</span><br></pre></td></tr></table></figure>

<blockquote>
<p>为什么这里会变成200？指导书中有提示：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">内核会发生地址翻译错误（Translation Fault），进而尝试跳转到异常处理函数（Exception Handler），</span><br><span class="line">该异常处理函数的地址为异常向量表基地址（`vbar_el1` 寄存器）加上 `0x200`。</span><br><span class="line"></span><br><span class="line">此时我们没有设置异常向量表（`vbar_el1` 寄存器的值是0），因此执行流会来到 `0x200` 地址，此处的代码为非法指令，会再次触发异常并跳转到 `0x200` 地址。</span><br><span class="line">使用 GDB 调试，在 GDB 中输入 `<span class="built_in">continue</span>` 后，按 Ctrl-C，可以观察到内核在 `0x200` 处无限循环。</span><br></pre></td></tr></table></figure>
</blockquote>
<p>然后，我注意到出错大概是在<code>arm64_elX_to_el1</code>这个符号邻近。我一看我去这不切换特权级吗？于是赶紧去把<code>arm64_elX_to_el1</code>这个函数搜出来了，并且一行行对比定位到出错的地方，然后就发现：</p>
<p><img src="/2024/07/27/chcore_lab/image-20240728150226658.png" alt="image-20240728150226658"></p>
<p>绷不住了！原来这是还没实现的内容呀:laughing:</p>
<h4 id="总结-1"><a href="#总结-1" class="headerlink" title="总结"></a>总结</h4><p>总之<code>make qemu</code>实现完lab1就跑起来了，是我看错指导书版本误会误大发了（建议银杏书官网和实验官网update一下……不过github那边也没指路让我去参考这两个就是了，哈哈……）。不过一下尝试了三四五种配环境思路，还学习了怎么用docker，也是一个不可多得的体验了。</p>
<h4 id="还有高手"><a href="#还有高手" class="headerlink" title="还有高手"></a>还有高手</h4><p>自那之后我就一直都使用的老版本builder容器（看了看那都是v1.0了）或者直接不run在docker来做实验，安然无事到了lab2。lab3中有要求一个<code>read_procmgr_elf_tool</code>，这个就是纯纯的sjtu提供的容器中自带的了，所以我也不得已继续花半天继续回到docker的问题……</p>
<p>Recall，之前是docker pull不下来，设了pull的代理和阿里云镜像仓库代理都没用。所以我主要还是先在尝试自建代理服务这一路，相关文章：</p>
<p><a target="_blank" rel="noopener" href="https://baijiahao.baidu.com/s?id=1802363672117972863&wfr=spider&for=pc">自建Docker镜像加速服务，免费且简单，服务器VPS、NAS皆可用</a></p>
<p><a target="_blank" rel="noopener" href="https://www.bilibili.com/read/cv35326945/?jump_opus=1">Docker加速解决方法</a></p>
<p>这个貌似确实比以前快了一些，但依旧还是会失败。焦头烂额了许久，最后终于找到了一个虽然略曲折但能行的方法：</p>
<p><a target="_blank" rel="noopener" href="https://wkdaily.cpolar.cn/archives/gc">使用Github Action 构建docker镜像</a></p>
<p>相当于是白嫖了下github的workflow，让它打包上传到github然后再从github下载。不得不说也是思路清奇，有一种所有网络问题都可以这么解的感觉。</p>
<p>然后从这下下来的会打两层包，一层zip一层tar.gz，解压完这两层之后再用<code>docker load -i filename</code>即可。</p>
<h1 id="Lab2-内存管理"><a href="#Lab2-内存管理" class="headerlink" title="Lab2: 内存管理"></a>Lab2: 内存管理</h1><p>TODO 结合整体架构，再进行一遍内存管理的梳理</p>
<p>本实验主要目的在于让同学们熟悉内核启动过程中对<strong>内存的初始化</strong>和内核启动后对<strong>物理内存和页表的管理</strong>，包括三个部分：物理内存管理、页表管理、缺页异常处理。</p>
<p>本实验（以及之后的实验）使用<code>expect</code>工具进行自动化评分，你可能需要先在你的环境中安装<code>expect</code>，具体方法因你使用的环境而异。</p>
<p>ChCore采用了buddy进行大内存分配和在此基础上的slab进行小内存分配。同时，采用了四级页表进行地址的映射。</p>
<h2 id="物理内存管理"><a href="#物理内存管理" class="headerlink" title="物理内存管理"></a>物理内存管理</h2><h3 id="Buddy-system"><a href="#Buddy-system" class="headerlink" title="Buddy system"></a>Buddy system</h3><p>伙伴系统大概就是按照2的幂次进行order的划分，每个order对应2^order个页。分配的时候拆解，释放的时候合并。具体结构如下图所示：</p>
<p><img src="/2024/07/27/chcore_lab/image-20240730153902396.png" alt="image-20240730153902396"></p>
<p><img src="/2024/07/27/chcore_lab/image-20240729140919170.png" alt="image-20240729140919170"></p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">/ * The layout of each physmem:</span><br><span class="line"> * | metadata (npages * <span class="keyword">sizeof</span>(<span class="keyword">struct</span> page)) | start_vaddr ... (npages *</span><br><span class="line"> * PAGE_SIZE) | */</span><br></pre></td></tr></table></figure>

<p>此为buddy内存分配的一个内存池的典型结构，每页物理内存页对应一个<code>struct page</code>结构体对象。</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">page</span> &#123;</span></span><br><span class="line">        <span class="comment">/* Free list */</span></span><br><span class="line">        <span class="class"><span class="keyword">struct</span> <span class="title">list_head</span> <span class="title">node</span>;</span></span><br><span class="line">        <span class="comment">/* Whether the correspond physical page is free now. */</span></span><br><span class="line">        <span class="type">int</span> allocated;</span><br><span class="line">        <span class="comment">/* The order of the memory chunk that this page belongs to. */</span></span><br><span class="line">        <span class="type">int</span> order;</span><br><span class="line">        <span class="comment">/* Used for ChCore slab allocator. */</span></span><br><span class="line">        <span class="type">void</span> *slab;</span><br><span class="line">        <span class="comment">/* The physical memory pool this page belongs to */</span></span><br><span class="line">        <span class="class"><span class="keyword">struct</span> <span class="title">phys_mem_pool</span> *<span class="title">pool</span>;</span></span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>

<p>我们将这些page对象以链表形式组织，对这些meta data的操作管理，来实现对buddy整个内存系统的管理。</p>
<p>我本来最直观的想法是迭代实现这个向上合并or向下分裂的过程，不过代码注释要求了使用递归（确实让我豁然开朗了一下），我于是也尽量将递归包括主体和对外接口都写得更优美一点了。</p>
<p>这也是我第一次实现buddy内存分配，以往都是简单知道概念。当时了解到这个算法就觉得非常惊艳，现在真正地去实现它，更感受到它的优美，包括但不限于对伙伴块的识别、合并分裂的实现和相关思想等。总的来说还是干货满满收获巨大，虽然还是遇到了一些曲折（见小品环节）。</p>
<h3 id="slab"><a href="#slab" class="headerlink" title="slab"></a>slab</h3><p>slab用于管理小内存对象。它为多个阶级的对象大小定义了多个内存池。具体结构可参考下图：</p>
<p><img src="/2024/07/27/chcore_lab/image-20240729223608682.png" alt="image-20240729223608682"></p>
<p>感觉最复杂的部分还是它已经帮我们写好的数据结构。</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 对应 kmem_cache</span></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">slab_pointer</span> &#123;</span></span><br><span class="line">        <span class="class"><span class="keyword">struct</span> <span class="title">slab_header</span> *<span class="title">current_slab</span>;</span></span><br><span class="line">        <span class="class"><span class="keyword">struct</span> <span class="title">list_head</span> <span class="title">partial_slab_list</span>;</span></span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="comment">/* slab_header resides in the beginning of each slab (i.e., occupies the first slot). */</span></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">slab_header</span> &#123;</span></span><br><span class="line">        <span class="comment">/* The list of free slots, which can be converted to struct slab_slot_list. */</span></span><br><span class="line">        <span class="type">void</span> *free_list_head;</span><br><span class="line">        <span class="comment">/* Partial slab list. */</span></span><br><span class="line">        <span class="class"><span class="keyword">struct</span> <span class="title">list_head</span> <span class="title">node</span>;</span></span><br><span class="line"></span><br><span class="line">        <span class="type">int</span> order;</span><br><span class="line">        <span class="type">unsigned</span> <span class="type">short</span> total_free_cnt; <span class="comment">/* MAX: 65536 */</span></span><br><span class="line">        <span class="type">unsigned</span> <span class="type">short</span> current_free_cnt;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>

<p>其中，每个slab的第一个obj被分配存储<code>free_list_head</code>，接下来链接<code>free_list_head</code>。<code>free_list_head</code>没有元数据结构，而是直接在obj首部加一个地址指向下一个空闲的obj。并且这个链表不一定是连续的，每次申请释放的时候直接头插尾插就行了，毕竟整个地址空间其实都算知道，就是slab的地址。</p>
<p>然后，要获取<code>partial_slab_list</code>的结点对应的<code>slab_header</code>结构体，只需要使用类似这样的宏就可以：</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">define</span> container_of_safe(ptr, type, field) (&#123; \</span></span><br><span class="line"><span class="meta">	typeof (ptr) __ptr = (ptr); \</span></span><br><span class="line"><span class="meta">	type *__obj = container_of(__ptr, type, field); \</span></span><br><span class="line"><span class="meta">	(__ptr ? __obj : NULL); \</span></span><br><span class="line"><span class="meta">&#125;)</span></span><br></pre></td></tr></table></figure>

<p>另，还用了个这样的结构：</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/* Each free slot in one slab is regarded as slab_slot_list. */</span></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">slab_slot_list</span> &#123;</span></span><br><span class="line">        <span class="type">void</span> *next_free;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>

<p>它不同于buddy的每页都有一个对应的page_t对象，是采用了一个指针直接链接的形式。</p>
<h2 id="页表"><a href="#页表" class="headerlink" title="页表"></a>页表</h2><p>ChCore在内核空间（<code>0xffff_ff00_0000_0000</code> 之后的地址）中，为了简单起见，虚拟地址和物理地址都是线性映射的，也即转为<code>vaddr + KBASE</code>，<code>KBASE</code>表示了虚拟地址空间的起始地址，故而可以通过<code>virt_to_phys</code>等函数进行映射。然后在此基础上，再将顶层的地址空间映射到栈对应页。</p>
<p>并且值得注意的是，包括测试环节我们也一直是使用的内核页表，这几个函数真正用在内核中大概还是在启动创建线程之后。</p>
<p>页表翻译的过程由MMU自动完成，我们只需把页表的物理地址存储在页表寄存器ttbr1_el1或ttbr0_el1即可。</p>
<blockquote>
<p>在 AArch64 架构的 EL1 异常级别存在两个页表基址寄存器：<code>ttbr0_el1</code><a target="_blank" rel="noopener" href="https://github.com/SJTU-IPADS/OS-Course-Lab/tree/ChCore-Lab1#user-content-fn-ttbr0_el1-8136733660332040a9f5e53c1035c9a2">1</a> 和 <code>ttbr1_el1</code><a target="_blank" rel="noopener" href="https://github.com/SJTU-IPADS/OS-Course-Lab/tree/ChCore-Lab1#user-content-fn-ttbr1_el1-8136733660332040a9f5e53c1035c9a2">2</a>，分别用作虚拟地址空间低地址和高地址的翻译。那么什么地址范围称为“低地址”，什么地址范围称为“高地址”呢？这由 <code>tcr_el1</code> 翻译控制寄存器<a target="_blank" rel="noopener" href="https://github.com/SJTU-IPADS/OS-Course-Lab/tree/ChCore-Lab1#user-content-fn-tcr_el1-8136733660332040a9f5e53c1035c9a2">3</a>控制，该寄存器提供了丰富的可配置性，可决定 64 位虚拟地址的高多少位为 <code>0</code> 时，使用 <code>ttbr0_el1</code> 指向的页表进行翻译，高多少位为 <code>1</code> 时，使用 <code>ttbr1_el1</code> 指向的页表进行翻译<a target="_blank" rel="noopener" href="https://github.com/SJTU-IPADS/OS-Course-Lab/tree/ChCore-Lab1#user-content-fn-ttbr-sel-8136733660332040a9f5e53c1035c9a2">4</a>。</p>
<p>0xffff_ff00_0000_0000为ChCore的虚拟地址开头，而0xffff_0000_0000_0000开始为高地址，所以是ttbr1_el1控制内核地址空间，ttbr0_el1控制用户地址空间。</p>
</blockquote>
<p>值得注意的是在mappages的时候需要在第三层就退出，然后手动映射，不然会导致在<code>get_next_ptp</code>中它帮我们申请一页物理地址不是我们想要的内存，导致内存泄漏。</p>
<p>这边可以回顾一下xv6的接口，是控制最后一次不alloc，然后返回下一次的pte。</p>
<h2 id="缺页中断"><a href="#缺页中断" class="headerlink" title="缺页中断"></a>缺页中断</h2><blockquote>
<p>当处理器发生缺页异常时，它会将发生错误的虚拟地址存储于 <code>FAR_ELx</code> 寄存器中，并触发相应的异常处理流程。ChCore 对该异常的处理最终实现在 <code>kernel/arch/aarch64/irq/pgfault.c</code> 中的 <code>do_page_fault</code> 函数。本次实验暂时不涉及前面的异常初步处理及转发相关内容，我们仅需要关注操作系统是如何处缺页异常的。</p>
<p><img src="/2024/07/27/chcore_lab/image-20240801125324310.png" alt="image-20240801125324310"></p>
</blockquote>
<p>这部分填空也是比较简单，在此不提具体的实现细节，不过可以了解一下这边中断相关和vmr相关的整体框架。</p>
<p>ChCore是多线程微内核实现，一个进程拥有一个vmspace，为进程虚拟地址空间的抽象，每个进程的vmspace指针都存在其对应的per-CPU字段中。一个vmspace被切分为多个vmregion，代表一段逻辑连续、权限相同的内存，然后vmr记录了这段region对应的物理对象（PMO），PMO里又记录了相应的物理地址。</p>
<p>因此，想要处理缺页异常，首先需要找到当前进程发生页错误的虚拟地址所处的 VMR，进而才能得知其对应的物理地址，从而在页表中完成映射。</p>
<blockquote>
<p>TODO    其实这里我还是不大懂，已知页表和va那直接查页表不就行了吗，为啥还得这么复杂搞什么PMO……希望继续做下去实验能给我答案。</p>
</blockquote>
<p>缺页处理主要针对 <code>PMO_SHM</code> 和 <code>PMO_ANONYM</code> 类型的 PMO，这两种 PMO 的物理页是在访问时按需分配的。</p>
<p>缺页处理逻辑为首先尝试检查 PMO 中当前 fault 地址对应的物理页是否存在（通过 <code>get_page_from_pmo</code> 函数尝试获取 PMO 中 offset 对应的物理页）。若对应物理页未分配，则需要分配一个新的物理页，再将页记录到 PMO 中，并增加页表映射。若对应物理页已分配，则只需要修改页表映射即可。</p>
<h2 id="小品环节-1"><a href="#小品环节-1" class="headerlink" title="小品环节"></a>小品环节</h2><h3 id="Buddy-system-1"><a href="#Buddy-system-1" class="headerlink" title="Buddy system"></a>Buddy system</h3><p>【详情见buddy相关初次commit】</p>
<p>本来是打算仅有低地址的buddy（或者说第偶数个？）真正代表了本块的order数。这样的话可以减少一次order赋值，增加些微的效率，如下图所示（最左那个内部省略，4121，跟右边差不多）。</p>
<p><img src="/2024/07/27/chcore_lab/image-20240730124409354.png" alt="image-20240730124409354"></p>
<p>然而之后发现这样其实算是不对称的。。。因为这隐形规定了你split的时候需要先split最右，然后merge的时候也需要从右向左merge（也即必须前一个块就位了你这个块才能merge），也即split的时候是先割地址更高的块，而merge要求先回收低地址的块。</p>
<p>所以，当先释放高地址的块，再释放低地址的块的时候，会出问题，导致只能merge递归一次而不能继续向上递归：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">order[0] free = 0</span><br><span class="line">order[1] free = 0</span><br><span class="line">order[2] free = 0</span><br><span class="line">order[3] free = 2</span><br><span class="line">order[4] free = 2</span><br><span class="line">order[5] free = 1</span><br><span class="line">order[6] free = 0</span><br><span class="line">order[7] free = 1</span><br><span class="line">order[8] free = 0</span><br><span class="line">order[9] free = 0</span><br><span class="line">order[10] free = 0</span><br><span class="line">order[11] free = 0</span><br><span class="line">order[12] free = 1</span><br><span class="line">order[13] free = 29</span><br></pre></td></tr></table></figure>

<h3 id="细粒度内核页表TODO"><a href="#细粒度内核页表TODO" class="headerlink" title="细粒度内核页表TODO"></a>细粒度内核页表TODO</h3><blockquote>
<p>思考题 6：为了简单起见，在 ChCore 实验 Lab1 中没有为内核页表使用细粒度的映射，而是直接沿用了启动时的粗粒度页表，请思考这样做有什么问题。</p>
</blockquote>
<p>感觉还是效率问题吧。。。有点像经典的读放大问题。</p>
<p>隔壁xv6是直接进行完细粒度映射，才开启MMU的。</p>
<blockquote>
<p>挑战题 7：使用前面实现的 <code>page_table.c</code> 中的函数，在内核启动后的 <code>main</code> 函数中重新配置内核页表，进行细粒度的映射。</p>
</blockquote>
<p>TODO</p>
<p>粗粒度的映射转化为细粒度的映射，本质上其实是将每个L2页表的块表项转化为指向一张L3页表的页表项，也即快表项和L3页表的一一映射。同时，内核这部分地址空间又比较敏感比较重要，所以其实策略有两种（也都大差不差）：</p>
<ol>
<li><p>建一个全新的三级页表，最后再修改<code>ttbr1_el1</code>寄存器</p>
<blockquote>
<p>注，0xffff_ff00_0000_0000为ChCore的虚拟地址开头，而0xffff_0000_0000_0000开始为高地址，所以是ttbr1_el1而非ttbr0_el1控制。</p>
</blockquote>
<p><img src="/2024/07/27/chcore_lab/image-20240801011820364.png" alt="image-20240801011820364"></p>
<p>这个精准卡在改完页表之后的下一行。。。</p>
</li>
<li><p>在原有基础上修改，只不过，walk到L2就停下，然后新建一张L3页表，等映射完一张L3页表的所有表项后才更换L2页表的块表项，也即本来一次映射的是PAGE_SIZE，现在映射的是<code>PAGE_SIZE*PTE_NUM</code>。</p>
<p>这个貌似卡在访问栈出错了之类的，刷新tlb也没屁用</p>
<figure class="highlight applescript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">Taking exception <span class="number">3</span> [Prefetch Abort]</span><br><span class="line">...<span class="keyword">from</span> EL1 <span class="keyword">to</span> EL1</span><br><span class="line">...<span class="keyword">with</span> ESR <span class="number">0x21</span>/<span class="number">0x8600000f</span></span><br><span class="line">...<span class="keyword">with</span> FAR <span class="number">0xffffff0000091bb8</span></span><br><span class="line">...<span class="keyword">with</span> ELR <span class="number">0xffffff0000091bb8</span></span><br><span class="line">...<span class="keyword">to</span> EL1 PC <span class="number">0x200</span> PSTATE <span class="number">0x3c5</span></span><br><span class="line">Taking exception <span class="number">3</span> [Prefetch Abort]</span><br><span class="line">...<span class="keyword">from</span> EL1 <span class="keyword">to</span> EL1</span><br><span class="line">...<span class="keyword">with</span> ESR <span class="number">0x21</span>/<span class="number">0x86000004</span></span><br><span class="line">...<span class="keyword">with</span> FAR <span class="number">0x200</span></span><br><span class="line">...<span class="keyword">with</span> ELR <span class="number">0x200</span></span><br><span class="line">...<span class="keyword">to</span> EL1 PC <span class="number">0x200</span> PSTATE <span class="number">0x3c5</span></span><br></pre></td></tr></table></figure>

<figure class="highlight applescript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">Taking exception <span class="number">3</span> [Prefetch Abort]</span><br><span class="line">...<span class="keyword">from</span> EL1 <span class="keyword">to</span> EL1</span><br><span class="line">...<span class="keyword">with</span> ESR <span class="number">0x21</span>/<span class="number">0x8600000f</span></span><br><span class="line">...<span class="keyword">with</span> FAR <span class="number">0xffffff000008f10c</span></span><br><span class="line">...<span class="keyword">with</span> ELR <span class="number">0xffffff000008f10c</span></span><br><span class="line">...<span class="keyword">to</span> EL1 PC <span class="number">0x200</span> PSTATE <span class="number">0x3c5</span></span><br></pre></td></tr></table></figure>

<p>这两个地方都是用了sp的地方。。【第一个在get_pages的第一句，第二个在紧随ret之前的某句，并且gdb调和实际运行的地方不一样】然而我看sp地址也很正常，所以真的搞不明白，只是把一页映射到sp上啊，也不会损失什么吧。。。更何况我地址也没问题，真是人类迷惑行为。</p>
</li>
</ol>
<p>我这两种方法都试了，奈何不知道为什么一直卡主不动。。。（我也不知道什么问题，貌似直接没办法从我写的一个专门作用于这种映射的函数返回到main里，产生了个非法地址越界，看起来好像是栈出了问题但我也不知道怎么回事。。。）</p>
<p>真的搞不懂，感觉各种细枝末节包括权限设置什么的都没错。</p>
<figure class="highlight avrasm"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">ffffff0000096438 &lt;set_ttbr0_el1&gt;:</span><br><span class="line"><span class="symbol">ffffff0000096438:</span>	d5182000 	msr	ttbr0_el1, x0</span><br><span class="line"><span class="symbol">ffffff000009643c:</span>	d5033fdf 	isb</span><br><span class="line"><span class="symbol">ffffff0000096440:</span>	d65f03c0 	<span class="keyword">ret</span></span><br><span class="line"><span class="symbol">ffffff0000096444:</span>	<span class="number">00000000</span> 	udf	<span class="meta">#0</span></span><br></pre></td></tr></table></figure>

<p>0xffffff000008f10c</p>
<p>ffffff000008f108</p>
<p>ffffff000008ee6c</p>
<p>想想真没问题吗。。。。我感觉是没问题啊。。。。总之我着实不知道怎么回事，还是先交给时间吧</p>
<p>都是从0开始映射，映射到这个指定值</p>
<figure class="highlight kotlin"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">ffffff0003f00000 	可以<span class="keyword">return</span></span><br><span class="line">ffffff0005e00000 	可以<span class="keyword">return</span></span><br><span class="line">ffffff0005f00000   	main里<span class="keyword">return</span>失败</span><br><span class="line">ffffff0006e00000   	第二次<span class="keyword">return</span>失败</span><br><span class="line">ffffff0007e00000 	<span class="keyword">return</span>失败</span><br></pre></td></tr></table></figure>

<p><img src="/2024/07/27/chcore_lab/image-20240801114707723.png" alt="image-20240801114707723"></p>
<p><img src="/2024/07/27/chcore_lab/image-20240801114718975.png" alt="image-20240801114718975"></p>
<p>而且很奇怪，在main中查出来和init里的权限是相反的。。。。</p>
<h3 id="PM"><a href="#PM" class="headerlink" title="PM"></a>PM</h3><p>本来学了个类似这样的可变参数宏的新活想用上去：</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">define</span> map_range_in_pgtbl(...) _map_range_in_pgtbl(__VA_ARGS__, 0)</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> _map_range_in_pgtbl(pgtbl, va, pa, len, flags, ...) map_range_in_pgtbl_impl(pgtbl, va, pa, len, flags)</span></span><br><span class="line"><span class="type">int</span> <span class="title function_">map_range_in_pgtbl_impl</span><span class="params">(<span class="type">void</span> *pgtbl, <span class="type">int</span> va, <span class="type">int</span> pa, <span class="type">size_t</span> len, <span class="type">int</span> flags)</span>;</span><br></pre></td></tr></table></figure>

<p>奈何用完之后才想起来别的文件是预编译为链接文件的，而宏作用在更早的阶段，所以这样是不行的，会引发链接错误。</p>
<h1 id="Lab3-进程与线程"><a href="#Lab3-进程与线程" class="headerlink" title="Lab3: 进程与线程"></a>Lab3: 进程与线程</h1><blockquote>
<p>在实验 1 和实验 2 中，已经完成了内核的启动和物理内存的管理，以及一个可供用户进程使用的页表实现。现在，我们将一步一步支持用户态程序的运行。</p>
</blockquote>
<p>实验 3 相较于实验 1 和实验 2 开放了部分用户态程序的代码，<code>user</code> 文件夹下提供了 <code>chcore-libc</code> 及 <code>system-services</code> 文件夹，并在根目录下添加了 <code>ramdisk</code> 文件夹。</p>
<ul>
<li><code>ramdisk</code>。所有在 <code>ramdisk</code> 目录下的文件将被放入内核镜像的文件系统中。</li>
<li><code>chcore-libc</code>。基于 <code>musl-libc</code> 进行修改以配合内核进行管理及系统调用，所有对 <code>musl-libc</code> 的修改均在 <code>chcore-libc/libchcore</code>中，实际编译时将使用脚本进行override。</li>
<li><code>system-services</code>。存放一些基本的系统服务，除了在 <code>ramdisk</code> 中已经包含的，还有 <code>tmpfs</code> 和 <code>procmgr</code>。<code>tmpfs</code> 是 ChCore 基本的内存文件系统，后续实验中将会有所涉及。<code>procmgr</code> 是 ChCore 的<strong>进程管理器</strong>，所有代码均以源代码形式给出，其中包含了创建进程、加载 elf 文件等操作，感兴趣的同学可以阅读。</li>
</ul>
<h2 id="访问控制"><a href="#访问控制" class="headerlink" title="访问控制"></a>访问控制</h2><h3 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h3><p>在 ChCore 中，内核提供给用户的一切资源均采用 <strong>Capability</strong> 机制进行管理。ChCore 微内核采用“Everything is an object”的设计理念，它将用户态能够进行操作的资源统一抽象成<strong>内核对象（kernel object）</strong>。这和UNIX操作系统中经典抽象“Everything is a file”类似，都是旨在提供简洁而统一的资源抽象。</p>
<p>ChCore微内核中共提供了7种类型的内核对象，分别是 cap 组对象（cap_group）、线程对象（thread）、物理内存对象（pmo）、地址空间对象（vmspace）、通信对象（connection 和 notification）、中断对象（irq）。每种内核对象定义了若干可以被用户态调用的操作方法，比如为线程对象设置优先级等调度信息、将一个物理内存对象映射到一个地址空间对象中等。</p>
<p>为了能够使用户态调用内核对象定义的方法，ChCore 微内核需要提供<strong>内核对象命名机制</strong>，即为一个内核对象提供<strong>在用户态相应的标识符</strong>。类似地，宏内核操作系统中的文件对象（file）在用户态的识别符是 fd，这就是一种命名机制。ChCore 采用 <strong>Capability</strong> 作为内核对象在用户态的标识符。</p>
<p>在 ChCore 微内核操作系统上运行的应用程序在内核态对应一个 cap 组对象，该对象中记录着该应用程序能够操作的全部内核对象。也即，<strong>ChCore 的一个进程是一些对特定内核对象享有相同的 Capability 的线程的集合，通过 capability 的设计，每个进程拥有独立的内核对象命名空间。</strong>ChCore 中的每个进程至少包含一个主线程，也可能有多个子线程，而每个线程则从属且仅从属于一个进程。同时，子进程也视为父进程的cap group中的一个slot。</p>
<blockquote>
<p>它这类比还蛮有意思的。在Linux中，包括内存管理、文件系统、进程本身、IO外设等的Metadata，都可以是文件（或者也不能这么说，我感觉文件形式更多时候其实还是只作为一个面向用户态的接口的……）；而在ChCore中，这些Metadata则以对象的形式表现。文件描述符fd是用于访问一个文件，实际上就代表了当前上下文对该文件具有一种可以访问的“Capability”。</p>
<p>而且，进程的含义其实是对整个系统的一个小型抽象，有自己的逻辑和数据。这个cap_group的角度也是非常精准。</p>
</blockquote>
<p>在实现中，一个 <code>cap_group</code> 作为一个进程的抽象，是指针数组，存储指向内核对象的指针。</p>
<p>Capability 在用户态看来是 cap 组的索引。当授权某个进程访问一个内核对象时，操作系统内核首先在这个进程对应的 cap 组中分配一个空闲的索引，然后把内核对象的指针填写到该索引位置，最后把索引值作为 capability 返回给用户态即可。【这就是非常FD的操作了】</p>
<p>用户态进程中的所有线程隶属于同一个 cap 组，而该 cap 组中非空闲的索引值即为该进程拥有的所有 capability，也就是该进程中所有线程能够操作的内核对象、即所有能够访问的资源。【这里其实也体现了线程和进程的概念之差，拥有共通共享的一些资源】</p>
<p>每个进程获取 capability 的方式有三种。</p>
<ol>
<li>在被创建时由父进程赋予；（fork）</li>
<li>在运行时向微内核申请获得；（grant）</li>
<li>由其他进程授予。（grant传播）</li>
</ol>
<p>Capability还能实现进程协作。比如说，若该内核对象是一个物理内存对象，则两个进程可以通过把它映射到各自的地址空间中从而建立<strong>共享内存</strong>；若该内核对象是一个通信对象，则两个进程可以通过调用其提供的方法进行<strong>IPC交互</strong>。【66666这个角度很有意思】</p>
<h3 id="数据结构"><a href="#数据结构" class="headerlink" title="数据结构"></a>数据结构</h3><p>一个内核对象由<code>struct object</code>代表，其具体数据存储在<code>opaque</code>中。而一个内核对象对应在每个cap group的代表是<code>struct object_slot</code>，存储了对<code>struct object</code>的指针以及其他相关信息。</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 内核对象</span></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">object</span> &#123;</span></span><br><span class="line">	u64 type;</span><br><span class="line">	u64 size;</span><br><span class="line">	<span class="comment">/* Link all slots point to this object */</span></span><br><span class="line">	<span class="class"><span class="keyword">struct</span> <span class="title">list_head</span> <span class="title">copies_head</span>;</span></span><br><span class="line">	<span class="keyword">volatile</span> <span class="type">unsigned</span> <span class="type">long</span> refcount;</span><br><span class="line">	<span class="comment">/*</span></span><br><span class="line"><span class="comment">	 * opaque marks the end of this struct and the real object will be</span></span><br><span class="line"><span class="comment">	 * stored here. Now its address will be 8-byte aligned.</span></span><br><span class="line"><span class="comment">	 */</span></span><br><span class="line">	u64 opaque[];	<span class="comment">// 可变长度成员字段</span></span><br><span class="line">&#125;;</span><br><span class="line"><span class="comment">// cap group指向内核对象的slot</span></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">object_slot</span> &#123;</span></span><br><span class="line">	<span class="type">int</span> slot_id;</span><br><span class="line">	<span class="class"><span class="keyword">struct</span> <span class="title">cap_group</span> *<span class="title">cap_group</span>;</span></span><br><span class="line">	<span class="class"><span class="keyword">struct</span> <span class="title">object</span> *<span class="title">object</span>;</span></span><br><span class="line">	<span class="comment">/* link copied slots pointing to the same object */</span></span><br><span class="line">	<span class="class"><span class="keyword">struct</span> <span class="title">list_head</span> <span class="title">copies</span>;</span></span><br><span class="line">&#125;;</span><br><span class="line"><span class="comment">// cap group的指针数组</span></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">slot_table</span> &#123;</span></span><br><span class="line">	<span class="type">unsigned</span> <span class="type">int</span> slots_size;</span><br><span class="line">	<span class="comment">// xiunian: pointer array</span></span><br><span class="line">	<span class="class"><span class="keyword">struct</span> <span class="title">object_slot</span> **<span class="title">slots</span>;</span></span><br><span class="line"></span><br><span class="line">	<span class="type">unsigned</span> <span class="type">long</span> *full_slots_bmp;</span><br><span class="line">	<span class="type">unsigned</span> <span class="type">long</span> *slots_bmp;</span><br><span class="line">	<span class="class"><span class="keyword">struct</span> <span class="title">rwlock</span> <span class="title">table_guard</span>;</span></span><br><span class="line">&#125;;</span><br><span class="line"><span class="comment">// cap group</span></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">cap_group</span> &#123;</span></span><br><span class="line">	<span class="class"><span class="keyword">struct</span> <span class="title">slot_table</span> <span class="title">slot_table</span>;</span>	<span class="comment">// pointer array</span></span><br><span class="line">	<span class="type">int</span> thread_cnt;	<span class="comment">// The number of threads</span></span><br><span class="line">	<span class="type">badge_t</span> badge;	<span class="comment">// pid</span></span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>

<h2 id="特权与异常"><a href="#特权与异常" class="headerlink" title="特权与异常"></a>特权与异常</h2><p>AArch64采用“异常级别”这一概念定义程序执行时所拥有的特权级别，从低到高分别是 EL0、EL1、EL2 和 EL3。ChCore 中仅使用了其中的两个异常级别：EL0 和 EL1。其中，EL1 是内核模式，<code>kernel</code> 目录下的内核代码运行于此异常级别。EL0 是用户模式，<code>user</code> 目录下的用户库与用户程序代码运行在用户模式下。</p>
<p>在 AArch64 架构中，异常是指低特权级软件（如用户程序）请求高特权软件（例如内核中的异常处理程序）采取某些措施以确保程序平稳运行的系统事件【这个概括还挺精确的】，包含<strong>同步异常</strong>和<strong>异步异常</strong>：</p>
<ul>
<li>同步异常：<strong>通过直接执行指令产生的异常</strong>。同步异常的来源包括同步中止（synchronous abort）和一些特殊指令。当直接执行一条指令时，若取指令或数据访问过程失败，则会产生同步中止。此外，部分指令（包括 <code>svc</code> 等）通常被用户程序用于主动制造异常以请求高特权级别软件提供服务（如<strong>系统调用</strong>）。</li>
<li>异步异常：<strong>与正在执行的指令无关的异常</strong>。异步异常的来源包括普通中 IRQ、快速中断 FIQ 和系统错误 SError。IRQ 和 FIQ 是由其他与处理器连接的硬件产生的中断，系统错误则包含多种可能的原因。本实验不涉及此部分。</li>
</ul>
<p>发生异常后，处理器需要找到与发生的异常相对应的异常处理程序代码并执行。在 AArch64 中，存储于内存之中的异常处理程序代码被叫做异常向量（exception vector），而所有的异常向量被存储在一张异常向量表（exception vector table）中。AArch64 中的每个异常级别都有其自己独立的异常向量表，其虚拟地址由该异常级别下的异常向量基地址寄存器（<code>VBAR_EL3</code>，<code>VBAR_EL2</code> 和 <code>VBAR_EL1</code>）决定。每个异常向量表中包含 16 个条目，每个条目里存储着发生对应异常时所需执行的异常处理程序代码。如下图所示：</p>
<p><img src="/2024/07/27/chcore_lab/3-exception.png" alt="3-exception.png"></p>
<blockquote>
<p>FIQ（Fast Interrupt Request）是一种 ARM 架构中的中断类型，是特权模式中的一种，同时也属于异常模式一类。旨在提供比标准中断（IRQ）更高的优先级和更快的响应时间，用于高速数据传输或通道处理。</p>
<p>FIQ和IRQ是两种不同类型的中断，ARM为了支持这两种不同的中断，提供了对应的叫做FIQ和IRQ处理器模式（ARM有7种处理模式）。</p>
<p>为使FIQ模式响应更快，FIQ模式具有更多的影子（Shadow）寄存器。</p>
<p><img src="/2024/07/27/chcore_lab/image-20240807115729322.png" alt="image-20240807115729322"></p>
<p>FIQ 的优先级高于常规的 IRQ（Interrupt Request）。</p>
</blockquote>
<h2 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h2><h3 id="1-用户进程和线程"><a href="#1-用户进程和线程" class="headerlink" title="1.用户进程和线程"></a>1.用户进程和线程</h3><p>在 ChCore 中，第一个被创建的进程是 <code>procmgr</code>，是 ChCore 核心的系统服务。本实验将以创建 <code>procmgr</code> 为例探索在 ChCore 中如何创建进程，以及成功创建第一个进程后如何实现内核态向用户态的切换。</p>
<p>在内核完成必要的初始化之后，内核将会跳转到创建第一个用户程序的操作中，该操作通过调用 <code>create_root_thread</code> 函数完成，本函数完成第一个用户进程的创建。</p>
<p>创建用户程序至少需要包括创建对应的 <code>cap_group</code>、加载用户程序镜像并且切换到程序。</p>
<p><code>create_root_thread</code>的操作包括：</p>
<ol>
<li>从<code>procmgr</code>镜像中读取程序信息</li>
<li>调用<code>create_root_cap_group</code>创建第一个 <code>cap_group</code> 进程</li>
<li>创建第一个线程，加载着<code>procmgr</code>系统服务</li>
</ol>
<p>此外，用户程序也可以通过 <code>sys_create_cap_group</code> 系统调用创建一个全新的 <code>cap_group</code>。</p>
<p>由于 <code>cap_group</code> 也是一个内核对象，因此在创建 <code>cap_group</code> 时，需要通过 <code>obj_alloc</code> 分配全新的 <code>cap_group</code> 和 <code>vmspace</code> 对象（<code>TYPE_CAP_GROUP</code> 与 <code>TYPE_VMSPACE</code>）。对分配得到的 <code>cap_group</code> 对象，需要通过 <code>cap_group_init</code> 函数初始化并且设置必要的参数(Tip: size 参数已定义好 <code>BASE_OBJECT_NUM</code>)。对分配得到的 <code>vmspace</code> 对象则需要调用 <code>cap_alloc</code> 分配对应的槽（slot）。</p>
<blockquote>
<p>这部分的描述，可以看<code>docs/capability.md</code>，里面描述了cap的一般步骤：</p>
<ol>
<li><code>obj_alloc</code> allocates an object and returns a data area with user-defined length.</li>
<li>Init the object within the data area.</li>
<li><code>cap_alloc</code> allocate a cap for the inited object.</li>
</ol>
</blockquote>
<p>然而，完成 <code>cap_group</code> 的分配之后，用户程序并没有办法直接运行，因为<code>cap_group</code>只是一个资源集合的概念。<strong>线程才是内核中的调度执行单位</strong>，因此还需要进行线程的创建，将用户程序 ELF 的各程序段加载到内存中。</p>
<blockquote>
<p>练习 2: 在 <code>kernel/object/thread.c</code> 中完成 <code>create_root_thread</code> 函数，将用户程序 ELF 加载到刚刚创建的进程地址空间中。</p>
</blockquote>
<p>此处大概是这样的逻辑，先在内核地址空间虚拟地址kva映射对应的一块物理内存pa，然后在内核中将elf程序copy到pa中（<code>procmgr</code>已经包含在了kernel image中，所以只需一个<code>memcpy</code>即可），最后再把这个pa映射到用户虚拟地址空间中（每个section的具体地址在elf程序头表的ph_vaddr字段指定）。</p>
<p>值得注意的是，貌似在ChCore的建立第一个进程这一阶段用的是一个魔改版的elf格式？<strong>详情见小品环节1。</strong></p>
<blockquote>
<p>不过这里还是简单放一下经典elf文件格式吧。</p>
<p>ELF文件结构主要包括三个部分：ELF头、程序头表（可选，用于可执行文件和共享库）、节头表（用于目标文件和可执行文件）。</p>
<ul>
<li><p><strong>ELF头（ELF Header）</strong>：包含文件类型、架构、入口点、程序头表和节头表的偏移、表大小等基本信息。</p>
</li>
<li><p><strong>程序头表（Program Header Table）</strong>：描述程序执行所需的段（segments），如代码段、数据段等。</p>
</li>
<li><p><strong>节头表（Section Header Table）</strong>：描述文件中的各个节（sections），如符号表、字符串表等。</p>
</li>
</ul>
<p><img src="/2024/07/27/chcore_lab/d60c5639833356815b58909463619f7d.png" alt="img"></p>
<p><img src="/2024/07/27/chcore_lab/f66156cab150064bb3fe37b4c0d61d04.png" alt="img"></p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span> <span class="title">elf32_hdr</span>&#123;</span></span><br><span class="line">    <span class="type">unsigned</span> <span class="type">char</span> e_ident[EI_NIDENT];     <span class="comment">/* 魔数和相关信息 */</span></span><br><span class="line">    Elf32_Half    e_type;                 <span class="comment">/* 目标文件类型 */</span></span><br><span class="line">    Elf32_Half    e_machine;              <span class="comment">/* 硬件体系 */</span></span><br><span class="line">    Elf32_Word    e_version;              <span class="comment">/* 目标文件版本 */</span></span><br><span class="line">    Elf32_Addr    e_entry;                <span class="comment">/* 程序进入点 */</span></span><br><span class="line">    Elf32_Off     e_phoff;                <span class="comment">/* 程序头部偏移量 */</span></span><br><span class="line">    Elf32_Off     e_shoff;                <span class="comment">/* 节头部偏移量 */</span></span><br><span class="line">    Elf32_Word    e_flags;                <span class="comment">/* 处理器特定标志 */</span></span><br><span class="line">    Elf32_Half    e_ehsize;               <span class="comment">/* ELF头部长度 */</span></span><br><span class="line">    Elf32_Half    e_phentsize;            <span class="comment">/* 程序头部中一个条目的长度 */</span></span><br><span class="line">    Elf32_Half    e_phnum;                <span class="comment">/* 程序头部条目个数  */</span></span><br><span class="line">    Elf32_Half    e_shentsize;            <span class="comment">/* 节头部中一个条目的长度 */</span></span><br><span class="line">    Elf32_Half    e_shnum;                <span class="comment">/* 节头部条目个数 */</span></span><br><span class="line">    Elf32_Half    e_shstrndx;             <span class="comment">/* 节头部字符表索引 */</span></span><br><span class="line">&#125; Elf32_Ehdr;</span><br></pre></td></tr></table></figure>

<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span> <span class="title">elf32_phdr</span>&#123;</span></span><br><span class="line">  Elf32_Word  p_type;        <span class="comment">/* 段类型 */</span></span><br><span class="line">  Elf32_Off   p_offset;      <span class="comment">/* 段位置相对于文件开始处的偏移量 */</span></span><br><span class="line">  Elf32_Addr  p_vaddr;       <span class="comment">/* 段在内存中的地址 */</span></span><br><span class="line">  Elf32_Addr  p_paddr;       <span class="comment">/* 段的物理地址 */</span></span><br><span class="line">  Elf32_Word  p_filesz;      <span class="comment">/* 段在文件中的长度 */</span></span><br><span class="line">  Elf32_Word  p_memsz;       <span class="comment">/* 段在内存中的长度 */</span></span><br><span class="line">  Elf32_Word  p_flags;       <span class="comment">/* 段的标记 */</span></span><br><span class="line">  Elf32_Word  p_align;       <span class="comment">/* 段在内存中对齐标记 */</span></span><br><span class="line">&#125; Elf32_Phdr;</span><br></pre></td></tr></table></figure>

</blockquote>
<p>再之后调用<code>init_thread_ctx</code>进行上下文初始化，然后通过<code>sched</code>选取到第一个程序进行运行，最后再一系列辗转调用eret回到用户态，从而开始运行。</p>
<p>然而，此时 ChCore 尚未配置从用户模式（EL0）切换到内核模式（EL1）的相关内容，在尝试执行 <code>svc</code> 指令时会出错，故而接下来完成对异常处理的配置。</p>
<h3 id="2-异常向量表"><a href="#2-异常向量表" class="headerlink" title="2.异常向量表"></a>2.异常向量表</h3><p>在 ChCore 中，仅使用了 EL0 和 EL1 两个异常级别，因此仅需要对 EL1 异常向量表进行初始化即可。</p>
<p>在本实验中，ChCore 内除系统调用外所有的同步异常均交由 <code>handle_entry_c</code> 函数进行处理。遇到异常时，硬件将根据 ChCore 的配置执行对应的汇编代码，将异常类型和当前异常处理程序条目类型作为参数传递，对于 sync_el1h 类型的异常，跳转 <code>handle_entry_c</code> 使用 C 代码处理异常。对于 irq_el1t、fiq_el1t、fiq_el1h、error_el1t、error_el1h、sync_el1t 则跳转 <code>unexpected_handler</code> 处理异常。</p>
<p>由注释：</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">* The selected <span class="built_in">stack</span> pointer can be indicated by a suffix to the Exception Level:</span><br><span class="line">*  - t: SP_EL0 is used</span><br><span class="line">*  - h: SP_ELx is used</span><br></pre></td></tr></table></figure>

<p>可知依次需要跳转的标签名的后缀顺序为t-h-64-32，并且每个跳转指令之间需要按照0x80对齐，所以需要间隔31个nop指令：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">b sync_el1t</span><br><span class="line">.rept 31</span><br><span class="line">nop</span><br><span class="line">.endr</span><br><span class="line">b irq_el1t</span><br><span class="line">.rept 31</span><br><span class="line">nop</span><br><span class="line">.endr</span><br><span class="line">b fiq_el1t</span><br><span class="line">.rept 31</span><br><span class="line">nop</span><br><span class="line">.endr</span><br><span class="line">b error_el1t</span><br><span class="line">.rept 31</span><br><span class="line">nop</span><br><span class="line">.endr</span><br></pre></td></tr></table></figure>

<p>然后我也是之后看别人的代码才发现，原来还可以这么写，学到了：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">.macro	exception_entry	label</span><br><span class="line">	/* Each entry of the exeception table should be 0x80 aligned */</span><br><span class="line">	.align	7</span><br><span class="line">	b	\label</span><br><span class="line">.endm</span><br><span class="line"></span><br><span class="line">	exception_entry sync_el1t</span><br><span class="line">	exception_entry irq_el1t</span><br><span class="line">	exception_entry fiq_el1t</span><br><span class="line">	exception_entry error_el1t</span><br></pre></td></tr></table></figure>

<h3 id="3-系统调用"><a href="#3-系统调用" class="headerlink" title="3.系统调用"></a>3.系统调用</h3><p>通过异常进入到内核后，ChCore在<code>exception_enter</code> 宏进行现场保存，在<code>exception_exit</code>宏进行现场恢复。保存时在栈中应准备<code>ARCH_EXEC_CONT_SIZE</code>大小的空间。</p>
<p>完成保存后，需要进行<strong>内核栈切换</strong>，首先从<code>TPIDR_EL1</code>寄存器中读取到当前核的<code>per_cpu_info</code>（参考<code>kernel/include/arch/aarch64/arch/machine/smp.h</code>），从而拿到其中的<code>cpu_stack</code>地址。</p>
<p>在本实验中新加入了 <code>libc</code> 文件，用户态程序可以链接其编译生成的<code>libc.so</code>，并通过 <code>libc</code> 进行系统调用从而进行向内核态的异常切换。实验接下来将对 <code>printf</code> 函数（<code>user/chcore-libc/musl-libc/src/stdio/printf.c</code>）的调用链进行分析与探索。</p>
<p><code>printf</code> 函数调用了 <code>vfprintf</code>，其中文件描述符参数为 <code>stdout</code>。这说明在 <code>vfprintf</code> 中将使用 <code>stdout</code> 的某些操作函数。</p>
<p>在 <code>user/chcore-libc/musl-libc/src/stdio/stdout.c</code>中可以看到 <code>stdout</code> 的 <code>write</code> 操作被定义为 <code>__stdout_write</code>，之后调用到 <code>__stdio_write</code> 函数。</p>
<p>最终 <code>printf</code> 函数将调用到 <code>chcore_stdout_write</code>。</p>
<blockquote>
<p>思考 7: 尝试描述 <code>printf</code> 如何调用到 <code>chcore_stdout_write</code> 函数。</p>
<p>提示：<code>chcore_write</code> 中使用了文件描述符，<code>stdout</code> 描述符的设置在<code>user/chcore-libc/musl-libc/src/chcore-port/syscall_dispatcher.c</code> 中。</p>
<p>可以看到在<code>user/chcore-libc/musl-libc/src/chcore-port/syscall_dispatcher.c</code>中设置了stdout的默认fdop：</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">fd_ops</span> <span class="title">stdout_ops</span> =</span> &#123;</span><br><span class="line">        .read = chcore_stdio_read,</span><br><span class="line">        .write = chcore_stdout_write,</span><br><span class="line">        .close = chcore_stdout_close,</span><br><span class="line">        .poll = chcore_stdio_poll,</span><br><span class="line">        .ioctl = chcore_stdio_ioctl,</span><br><span class="line">        .fcntl = chcore_stdio_fcntl,</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>
</blockquote>
<p><code>chcore_stdout_write</code> 中的核心函数为 <code>put</code>，此函数的作用是向终端输出一个字符串。</p>
<p>从 <code>printf</code> 的例子我们也可以看到<strong>从通用 api 向系统相关 abi 的调用过程</strong>，并最终通过系统调用完成从用户态向内核态的异常切换。</p>
<h2 id="小品环节-2"><a href="#小品环节-2" class="headerlink" title="小品环节"></a>小品环节</h2><h3 id="ELF加载"><a href="#ELF加载" class="headerlink" title="ELF加载"></a>ELF加载</h3><p>不知道为什么，<code>procmgr</code>被设计为不是正规的ELF文件格式，而是魔改版ELF……</p>
<p>具体来说，我们可以看看编译生成<code>procmgr</code>镜像的cmake代码：</p>
<figure class="highlight cmake"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">add_custom_target</span>(</span><br><span class="line">    create-procmgr-bin ALL</span><br><span class="line">    <span class="keyword">COMMAND</span> echo <span class="string">&quot;build procmgr binary...&quot;</span></span><br><span class="line">    <span class="keyword">COMMAND</span> read_procmgr_elf_tool <span class="variable">$&#123;CMAKE_CURRENT_BINARY_DIR&#125;</span>/procmgr.srv</span><br><span class="line">    <span class="keyword">COMMAND</span> chmod <span class="number">666</span> elf_info.temp</span><br><span class="line">    <span class="keyword">COMMAND</span> cat elf_info.temp procmgr.bin &gt; procmgr</span><br><span class="line">    <span class="keyword">COMMAND</span> rm -f <span class="variable">$&#123;CMAKE_CURRENT_BINARY_DIR&#125;</span>/elf_info.temp</span><br><span class="line">    <span class="keyword">COMMAND</span> echo <span class="string">&quot;build procmgr success!&quot;</span></span><br><span class="line">    DEPENDS procmgr.srv procmgr.bin)</span><br></pre></td></tr></table></figure>

<p>其中，<code>procmgr.srv</code>为正统的ELF格式，通过<code>readelf</code>工具可读。它只包含elf header和程序头表。</p>
<blockquote>
<p>可以通过<code>readelf -h build/user/system-services/system-servers/procmgr/procmgr.srv</code>和<code>readelf -l build/user/system-services/system-servers/procmgr/procmgr.srv</code>来读取其elf头和程序头表。</p>
</blockquote>
<p>然后可以看到，他这里大概是做了这么个操作，首先是使用了他们docker环境自带的一个工具<code>read_procmgr_elf_tool</code>将这个.srv文件转化为了<code>elf_info.temp</code>，再把这个.tmp和.bin文件合二为一成为最终的<code>procmgr</code>映像。</p>
<p>我们可以来看看这个.tmp文件里到底存了啥，跟正宗elf有什么不一样。</p>
<p>首先这个是<code>elf_info.temp</code>：</p>
<p><img src="/2024/07/27/chcore_lab/image-20240805231453013.png" alt="image-20240805231453013"></p>
<p>这个是<code>procmgr.srv</code>：</p>
<p><img src="/2024/07/27/chcore_lab/image-20240805230347173.png" alt="image-20240805230347173"></p>
<p>可以看到，蓝色部分其实就跟.tmp文件的内容差不多，.tmp文件大概是对ELF格式进行了一定的魔改。具体来说，它照搬了程序头表基本不变（自.tmp文件的0x40开始的位置，小端），然后又对标准的ELF Header进行了增删魔改（而且还变成了大端形式），最终形成了这么一个大小为48(elf header)+56*3(phdr size)=216大小的首部。</p>
<p>这还不是最幽默的，还有一点，就是他还改了程序头表的<code>ph_offset</code>字段！</p>
<p><code>ph_offset</code>字段的原意是该程序头对应的segment离文件开始的偏移量，并且会按照其<code>ph_align</code>字段进行地址对齐。在.srv中，每个程序头表项的align都为0x1000（PAGE_SIZE），故而，其offset字段情况如下图所示：</p>
<p><img src="/2024/07/27/chcore_lab/image-20240806160045163.png" alt="image-20240806160045163"></p>
<p>然而，生成的<code>elf_info.temp</code>的第一个offset字段被置为了0，也就是说一个segment的起始地址应该为 文件起始地址+216(首部大小)+offset。</p>
<p><img src="/2024/07/27/chcore_lab/image-20240805232202424.png" alt="image-20240805232202424"></p>
<p><img src="/2024/07/27/chcore_lab/image-20240805232224641.png" alt="image-20240805232224641"></p>
<p>以上的这几种细节，以及全然未提及相关信息的指导书（只说加载ELF程序……但我寻思这也不是ELF啊），使我在这部分struggle了许久，对offset改来改去毫无思路，不清楚为什么读出来会是0，也不清楚是否需要按页对齐（反正对不对齐其实试出来都是错的hhh）。最终发现错误也比较偶然，大概是盯着那堆ELF相关宏抓耳挠腮时，开始好奇这个<code>#define ROOT_BIN_HDR_SIZE 216</code>的216是怎么来的，算了一下发现标准的ELF格式其实应该是232(64+56*3)才对，然后又想到之前配环境一通折腾时就看不懂的那段cmake指令，以及细看才发现前面读elf header时更是古怪（原谅我写的时候前面直接跳过没仔细看了……），才意识到原来用的不是标准ELF，而是魔改版的……</p>
<p>不过，我不大懂这里为啥要用魔改版这么复杂曲折，我翻了翻<a target="_blank" rel="noopener" href="https://github.com/WilliamX1/ChCore/blob/lab3/kernel/object/thread.c">往年的实验版本</a>包括隔壁xv6也都是用的标准ELF格式。难道是为了读取方便统一用8字节，或者节省image大小……但指导书怎么没提及这一点呢，莫非是我孤陋寡闻了……</p>
<blockquote>
<p>后续：</p>
<p>procmgr负责进程生态的管理，如果要新建进程，也是向procmgr发送相关消息即可，它会先读入elf，再调用<code>elf_so_loader_launch_process</code>，最终调用<code>launch_process_with_pmos_caps</code>函数进行和内核差不多的操作，如创建内存空间创建主线程等。这里就是一个非常纯粹的微内核了，创建进程这种大活都被放到了userspace。</p>
<p>可能就是因为这样，内核就仅保留一个小的魔改版elf了。</p>
</blockquote>
<h1 id="Lab4-多核调度与IPC"><a href="#Lab4-多核调度与IPC" class="headerlink" title="Lab4: 多核调度与IPC"></a>Lab4: 多核调度与IPC</h1><p>在本实验中，ChCore将支持在多核处理器上启动；实现多核调度器以调度执行多个线程；最后实现进程间通信IPC。代码部分都相对简单，更多还是需要理解IPC通信流程。</p>
<h2 id="多核启动"><a href="#多核启动" class="headerlink" title="多核启动"></a>多核启动</h2><p>为了让ChCore支持多核，我们需要考虑如下问题：</p>
<ol>
<li><p>如何启动多核，让每个核心执行初始化代码并开始执行用户代码？ </p>
<p><code>wait_until_smp_enabled</code>→<code>secondary_init_c</code>→</p>
<p><img src="/2024/07/27/chcore_lab/image-20240806193556997.png" alt="image-20240806193556997"></p>
<p><img src="/2024/07/27/chcore_lab/image-20240806193002773.png" alt="image-20240806193002773"></p>
</li>
<li><p>如何区分不同核心在内核中保存的数据结构（比如状态，配置，内核对象等）？</p>
<p>ChCore对于内核中需要每个CPU核心单独存一份的内核对象，利用一个数组来保存，CID作为数组的索引。</p>
<p>ChCore支持的核心数量为<code>PLAT_CPU_NUM</code>。</p>
<p>smp_get_cpu_id函数通过访问系统寄存器tpidr_el1来获取调用它的CPU核心的ID。</p>
</li>
<li><p> 如何保证内核中对象并发正确性，确保不会由于多个核心同时访问内核对象导致竞争条件？ </p>
</li>
</ol>
<blockquote>
<p>思考题 2：阅读汇编代码kernel/arch/aarch64/boot/raspi3/init/start.S, init_c.c以及kernel/arch/aarch64/main.c，解释用于阻塞其他CPU核心的secondary_boot_flag是物理地址还是虚拟地址？是如何传入函数enable_smp_cores中，又是如何赋值的（考虑虚拟地址/物理地址）？</p>
</blockquote>
<p>真无敌了我刚刚就在研究这个，结果他居然正好也问了。</p>
<p><code>enable_smp_cores</code>中的<code>secondary_boot_flag</code>为虚拟地址，此时已经开启了MMU，所以直接写入然后再保障缓存一致性就没什么问题。</p>
<p>然后在main中传入的这个<code>boot_flag</code>是物理地址，是通过main函数参数传递进来的：</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">void</span> <span class="title function_">main</span><span class="params">(<span class="type">paddr_t</span> boot_flag, <span class="type">void</span> *info)</span></span><br><span class="line">	<span class="comment">/* Other cores are busy looping on the boot_flag, wake up those cores */</span></span><br><span class="line">	<span class="title function_">enable_smp_cores</span><span class="params">(boot_flag)</span>;</span><br></pre></td></tr></table></figure>

<p>然后感觉前面的就都是地址了，应该都是靠的参数传。</p>
<h2 id="多核调度"><a href="#多核调度" class="headerlink" title="多核调度"></a>多核调度</h2><p>【要来到我的老本行了，激动激动】</p>
<p>ChCore对于调度策略的抽象可以看到也是经典的调度类模式。</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/* Provided Scheduling Policies */</span></span><br><span class="line"><span class="keyword">extern</span> <span class="class"><span class="keyword">struct</span> <span class="title">sched_ops</span> <span class="title">pbrr</span>;</span>	<span class="comment">/* Priority Based Round Robin */</span></span><br><span class="line"><span class="keyword">extern</span> <span class="class"><span class="keyword">struct</span> <span class="title">sched_ops</span> <span class="title">pbfifo</span>;</span>	<span class="comment">/* Priority Based FIFO */</span></span><br><span class="line"><span class="keyword">extern</span> <span class="class"><span class="keyword">struct</span> <span class="title">sched_ops</span> <span class="title">rr</span>;</span>	<span class="comment">/* Simple Round Robin */</span></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">sched_ops</span> &#123;</span></span><br><span class="line">    <span class="type">int</span> (*sched_init)(<span class="type">void</span>);</span><br><span class="line">    <span class="comment">// pnt, 将正在运行的线程放回就绪队列，然后在就绪队列中选择下一个需要执行的线程</span></span><br><span class="line">    <span class="type">int</span> (*sched)(<span class="type">void</span>);</span><br><span class="line">    <span class="type">int</span> (*sched_periodic)(<span class="type">void</span>);</span><br><span class="line">    <span class="type">int</span> (*sched_enqueue)(<span class="keyword">struct</span> thread * thread);</span><br><span class="line">    <span class="type">int</span> (*sched_dequeue)(<span class="keyword">struct</span> thread * thread);</span><br><span class="line">    <span class="comment">/* Debug tools */</span></span><br><span class="line">    <span class="type">void</span> (*sched_top)(<span class="type">void</span>) ;<span class="comment">// 打印当前所有核心上的运行线程以及等待线程的函数</span></span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>

<p>其他的就没啥好说了，因为毕竟调度这块还是比较经典的宏内核做法，这部分主要就是跟着写了个rr和初始化了一下时钟，大部分还是偏了解为主。这里就记录一点关于FPU的东西吧。</p>
<blockquote>
<p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/548957617#:~:text=%E5%9C%A8%E8%AE%BE%E8%AE%A1%E4%B8%8A%E4%B8%8B%E6%96%87%E8%B0%83%E5%BA%A6%E5%99%A8%E7%9A%84%E6%97%B6%E5%80%99%EF%BC%8C%E6%9C%89%E4%B8%89%E7%A7%8D%E8%AE%BE%E8%AE%A1%E6%96%B9%E6%A1%88">关于FPU</a></p>
<p><strong>内核线程没有FPU状态？</strong></p>
<ol>
<li><strong>内核线程通常不使用FPU</strong>：在许多操作系统中，内核线程主要负责执行内核态的任务，这些任务通常不涉及浮点运算，因此没有必要为这些线程保存和恢复FPU状态。</li>
<li><strong>性能考虑</strong>：保存和恢复FPU状态会增加线程切换的开销。如果内核线程不使用FPU，则不需要在切换时处理FPU状态，这可以提升系统性能。</li>
</ol>
<p><strong>软件浮点运算</strong></p>
<p>在没有FPU的情况下，浮点运算是通过一系列的整数运算和逻辑操作实现的。这通常涉及调用特定的库函数或由编译器生成相应的代码来模拟浮点运算。软件浮点运算的特点包括：</p>
<ol>
<li><strong>慢速</strong>：因为每一个浮点操作都需要多个机器指令来完成。</li>
<li><strong>复杂性</strong>：实现浮点运算的函数比较复杂，涉及到多步操作。</li>
</ol>
<p><strong>硬件浮点运算（使用FPU）</strong></p>
<p>FPU是专门用于执行浮点运算的硬件单元。使用FPU的特点包括：</p>
<ol>
<li><strong>快速</strong>：浮点运算可以在一个或几个时钟周期内完成，极大地提高了计算速度。</li>
<li><strong>简便</strong>：编译器可以直接生成使用FPU指令的代码，简化了浮点运算的实现。</li>
</ol>
<p>如果需要在内核线程中执行浮点运算，可以通过以下方式实现：</p>
<ol>
<li><strong>启用FPU使用</strong>：允许内核线程使用FPU，并在上下文切换时保存和恢复FPU状态。</li>
<li><strong>特定处理</strong>：在需要时，特定的内核线程可以启用FPU，进行计算，然后禁用FPU，并将结果返回。</li>
</ol>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">kernel_fpu_begin();      <span class="comment">// 开始使用FPU</span></span><br><span class="line"></span><br><span class="line">b = b * <span class="number">5</span> - <span class="number">1.5</span>;</span><br><span class="line">a = a * <span class="number">100</span> / <span class="number">6</span>;</span><br><span class="line"></span><br><span class="line">kernel_fpu_end();        <span class="comment">// 结束使用FPU</span></span><br></pre></td></tr></table></figure>

</blockquote>
<h2 id="进程IPC通信"><a href="#进程IPC通信" class="headerlink" title="进程IPC通信"></a>进程IPC通信</h2><p>【激动！】</p>
<p>在本部分，我们将实现ChCore的进程间通信，从而允许跨地址空间的两个进程可以使用IPC进行信息交换。</p>
<p><img src="/2024/07/27/chcore_lab/IPC-overview.png" alt="img"></p>
<p>ChCore的IPC接口不是传统的send/recv接口，而是采用了客户端/服务器模型，并且采取了简单的Thread Migration机制。接下来，将以一次IPC通信为例，介绍ChCore的IPC机制。</p>
<p>在具体的流程之前，我们可以先简单回想一下基于线程迁移的IPC是什么个形式。</p>
<p>大概是这样，Server那端会提供一个特殊的线程，仅在Client发送IPC请求时才会被调度执行。然后如果需要通信，双方需要先建立连接，从而对通信过程中需要的例如函数、参数以及共享内存等进行一个申请和初始化。连接建立后，Client中的线程A如果想发起IPC调用Server的某些函数，那么A就会把自己直接上下文切换到Server端，在Server端的进程上下文中执行完再迁移回到Client进程的上下文中。与此同时可以通过共享内存来实现信息的交流。</p>
<p>在ChCore中，Server那端特殊的线程即被称为<code>TYPE_SHADOW</code>。这些线程没有<strong>调度的</strong>上下文（也即时间片之类），会直接继承Client发起请求线程的时间片。与此同时，ChCore还有另一种特殊的shadow线程，类型被标记为<code>TYPE_REGISTER</code>，来实现兼容线程迁移的连接建立（而非传统send/recv）。</p>
<p>接下来，将介绍ChCore的具体实现。</p>
<h3 id="主要流程"><a href="#主要流程" class="headerlink" title="主要流程"></a>主要流程</h3><h4 id="Server-init"><a href="#Server-init" class="headerlink" title="Server init"></a>Server init</h4><p>Server调用<code>register_server</code>将自己注册为服务端。具体来说，该函数会通过系统调用<code>sys_register_server</code>注册三个回调函数，写入内核的meta data中（<code>struct thread</code>的<code>general_config</code>字段）。</p>
<ol>
<li><p><code>server_destructor</code>：析构器，仅记录其函数指针</p>
</li>
<li><p><code>client_register_handler</code>：创建连接回调，会为其创建对应的shadow线程（<code>TYPE_REGISTER</code>，下称register_cb thread）</p>
</li>
<li><p><code>server_handler</code>：Server的具体处理逻辑，暂时仅记录其函数指针</p>
<p>是最体现service本身具体功能的部分了。对于procmgr，其服务功能就是了解进程的状态并且进行管理；而对于pipe，其服务功能就是响应对管道的读写请求。</p>
</li>
</ol>
<p>至此，Server即处于监听状态，shadow线程register cb静默，直到Client端发来连接请求。</p>
<h4 id="连接建立"><a href="#连接建立" class="headerlink" title="连接建立"></a>连接建立</h4><ol>
<li><p>Client端初始化</p>
<p>Client调用<code>register_client</code>来主动建立IPC connection。</p>
<p>具体来说，该函数及其相关系统调用流程如下：</p>
<ol>
<li><p>申请一块物理内存pmo作为共享内存SHM，并且在自己的vmspace中映射</p>
</li>
<li><p>在双方的cap group创建SHM对象</p>
<blockquote>
<p>PS: 相信大家看到这应该也会和我有同样的疑惑，此处在Client上下文中是怎么获取Server的呢？</p>
<p>分析请见下一模块<code>相关细节-server cap</code></p>
</blockquote>
</li>
<li><p>在双方的cap group创建IPC connection对象</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">ipc_connection</span> &#123;</span></span><br><span class="line">	<span class="comment">// Note that all threads in the client process can use this connection.</span></span><br><span class="line">	<span class="class"><span class="keyword">struct</span> <span class="title">thread</span> *<span class="title">current_client_thread</span>;</span></span><br><span class="line">	<span class="class"><span class="keyword">struct</span> <span class="title">thread</span> *<span class="title">server_handler_thread</span>;</span></span><br><span class="line">	<span class="type">badge_t</span> client_badge;	<span class="comment">// pid</span></span><br><span class="line">    <span class="comment">// SHM相关信息，如在双方的cap和vaddr，以及SHM大小</span></span><br><span class="line">	<span class="class"><span class="keyword">struct</span> <span class="title">shm_for_ipc_connection</span> <span class="title">shm</span>;</span></span><br><span class="line">	<span class="comment">/* For resource recycle */</span></span><br><span class="line">	<span class="class"><span class="keyword">struct</span> <span class="title">lock</span> <span class="title">ownership</span>;</span></span><br><span class="line">	<span class="type">cap_t</span> conn_cap_in_client;</span><br><span class="line">	<span class="type">cap_t</span> conn_cap_in_server;</span><br><span class="line">	<span class="type">int</span> state;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure></li>
<li><p>重置register_cb thread</p>
<p>重置入口、栈地址等，并且设置参数为server handler。</p>
</li>
<li><p>上下文切换到register_cb thread，去完成Server端的初始化</p>
</li>
</ol>
</li>
<li><p>Server端初始化</p>
<p>Server端通过<code>register_cb thread</code>来进行连接的初始化。</p>
<p>具体来说，该函数及其相关系统调用<code>sys_ipc_register_cb_return</code>流程如下：</p>
<ol>
<li>创建shadow线程server handler</li>
<li>映射SHM到自己的vmspace</li>
<li>重置server handler thread</li>
<li>上下文切换回Client端线程，回到userspace</li>
</ol>
</li>
</ol>
<p>至此，连接成功建立，shadow线程server handler静默，直到Client端发送ipc请求。</p>
<h4 id="通信"><a href="#通信" class="headerlink" title="通信"></a>通信</h4><ol>
<li>Client端在共享内存中写入msg，包含请求函数和相关参数</li>
<li>调用系统调用<code>ipc_call</code>，上下文切换到Server端执行server handler</li>
<li>server handler执行结束后调用<code>ipc_return</code>（带返回结果），回到Client端上下文继续执行</li>
</ol>
<h3 id="相关细节"><a href="#相关细节" class="headerlink" title="相关细节"></a>相关细节</h3><h4 id="server-cap"><a href="#server-cap" class="headerlink" title="server cap"></a>server cap</h4><p><code>register_client</code>通过系统调用参数的server cap从而获取到其pmo的Server thread。然而既然用到了server cap那就说明server thread处在client的cap group中，那么Client是如何将想要连接的server加入到自己的cap group从而获取server cap的？</p>
<p>之前的实验告诉我们这两点：</p>
<ol>
<li>ChCore的第一个进程是procmgr</li>
<li>所有进程的创建都需要经过procmgr</li>
<li>子进程可以继承父进程的cap group</li>
<li>父进程的cap group会记录其所有子进程的cap</li>
</ol>
<p>所以，答案显而易见，世界是一个巨大的ipc：</p>
<ol>
<li>所有进程都是procmgr的子孙，故而都能按创建顺序继承部分进程cap。创建顺序是procmgr-&gt;system service-&gt;user process，故而，所有system service都有procmgr的句柄，所有用户进程都有所有系统服务的句柄。</li>
<li>所有进程都是procmgr的子孙，故而procmgr拥有所有进程的cap信息。client可以通过IPC向procmgr请求它所需要获取的服务的cap，procmgr会帮你填入<code>thread-&gt;cap_buffer</code>（&lt;int, int&gt;映射）。</li>
</ol>
<h4 id="thread-migration"><a href="#thread-migration" class="headerlink" title="thread migration"></a>thread migration</h4><p>可以看到，ChCore这边就是一个非常纯粹的Thread Migration实现逻辑。相比于Linux等还有些把进程线程概念稍微等同的倾向（虽然实际实现不怎么等同了），ChCore直接用cap group和thread来彻底切割了，process仅仅提供逻辑和一些资源环境，所以真正执行逻辑的线程就可以进程之间到处乱窜了。</p>
<p>只不过这个迁移实现确实还是没我之前想得那么高大上（）其实说白话，就相当于client thread主动放弃自己的CPU，然后定向把自己CPU丢给server thread，然后为了确保公平性就共享时间片这样。我原来还觉得可能是实体性的迁移，还觉得太牛逼了怎么实现的，不过你说这是线程迁移吧也确实，所以可能高度抽象的理论和具体实现之间总会有这种期望的落差哈哈……</p>
<p>不过可以看出，这样的线程迁移确实性能上会有些忧虑。虽然它也算是减少了原有IPC设计上的开销，比如参数的copy、数据传输多次send/recv同步开销以及client线程忙等待，但上下文切换带来的页表切换、特权级切换、Cache/TLB刷新、更少的编译优化等性能问题还是会让人担忧。</p>
<p>除此之外，值得注意的是，Server端只有一个register cb，但是每个连接都有对应的server handler。故而register的时候是需要retry的。</p>
<h4 id="信息交互"><a href="#信息交互" class="headerlink" title="信息交互"></a>信息交互</h4><p>关于信息交互，感觉它还算是提供了比较丰富的接口，可以通过共享内存交互，也可以有常规的返回值，还可以通过cap group，在<code>sys_ipc_call</code>的时候会把client的cap copy给server，然后return的时候会把server的cap copy给client。</p>
<ol>
<li><p>常规返回值</p>
<p>这个就比较典了，在<code>ipc_return</code>的时候设一下返回寄存器就差不多了。</p>
</li>
<li><p>capability</p>
<p>在server handler中或者client中可以设定想要拷贝给client的cap们：</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ipc_set_msg_return_cap_num(ipc_msg, <span class="number">1</span>);</span><br><span class="line">ipc_set_msg_cap(ipc_msg, <span class="number">0</span>, mpinfo-&gt;fs_cap);</span><br></pre></td></tr></table></figure>

<p>然后在<code>ipc_return</code>或者<code>ipc_call</code>中会调用<code>ipc_send_cap</code>，从而能够进行cap的传播授权。</p>
</li>
<li><p>共享内存</p>
<p>用来传递ipc msg。值得注意的是，很多地方在跟system service进行交互的时候，都是使用了这样的宏来作为创建消息时的icb（ipc control block，只用于client端）：</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">define</span> fsm_ipc_struct     (__fsm_ipc_struct_location())</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> lwip_ipc_struct    (__net_ipc_struct_location())</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> procmgr_ipc_struct (__procmgr_ipc_struct_location())</span></span><br></pre></td></tr></table></figure>

<p>这其实是为了性能起见，让每个thread都内置一个一对一的connection icb，而非像其他service一样支持多thread对一connection，从而提高系统服务的可扩展性（这点在鸿蒙论文也提到了）。</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/* ipc_struct for invoking system servers.</span></span><br><span class="line"><span class="comment"> * fsm_ipc_struct and lwip_ipc_struct are two addresses.</span></span><br><span class="line"><span class="comment"> * They can be used like **const** pointers.</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * If a system server is related to the scalability (multi-threads) of</span></span><br><span class="line"><span class="comment"> * applications, we should use the following way to make the connection with it</span></span><br><span class="line"><span class="comment"> * as per-thread.</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * For other system servers (e.g., process manager), it is OK to let multiple</span></span><br><span class="line"><span class="comment"> * threads share a same connection.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="type">ipc_struct_t</span> *__fsm_ipc_struct_location(<span class="type">void</span>);</span><br><span class="line"><span class="type">ipc_struct_t</span> *__net_ipc_struct_location(<span class="type">void</span>);</span><br><span class="line"><span class="type">ipc_struct_t</span> *__procmgr_ipc_struct_location(<span class="type">void</span>);</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment"> * **fsm_ipc_struct** is an address that points to the per-thread</span></span><br><span class="line"><span class="comment"> * system_ipc_fsm in the pthread_t struct.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="type">ipc_struct_t</span> *__fsm_ipc_struct_location(<span class="type">void</span>)</span><br><span class="line">&#123;</span><br><span class="line">        <span class="keyword">return</span> &amp;__pthread_self()-&gt;system_ipc_fsm;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>也因此，在写这类system service的消息结构体的时候需要尤其注意初始化问题……（本人后面在写lab5 FSM的时候就被坑得巨惨）它是直接的覆写（比如在<code>ipc_create_msg</code>中），不会帮你在覆写前memset一下。</p>
<p><img src="/2024/07/27/chcore_lab/image-20240809165526574.png" alt="image-20240809165526574"></p>
</li>
</ol>
<h1 id="Lab5-虚拟文件系统"><a href="#Lab5-虚拟文件系统" class="headerlink" title="Lab5: 虚拟文件系统"></a>Lab5: 虚拟文件系统</h1><p>虚拟文件系统（Virtual File System，VFS）提供了一个抽象层，使得不同类型的文件系统可以在应用程序层面以统一的方式进行访问。当应用程序发出文件操作请求时（如打开文件、读取文件等），这些请求首先会经过 VFS 层。VFS 根据文件路径解析出具体的文件系统，然后将操作请求委托给相应的文件系统驱动程序执行。</p>
<p>在 ChCore 中，我们通过 FSM 系统服务以及 FS_Base 文件系统 wrapper 将不同的文件系统整合起来，给运行在 ChCore 上的应用提供了统一的抽象。只要实现了 FSBase 和 FSWrapper 的接口的 IPC 服务，都可以成为一个文件系统示例。【这就是一种多态了】</p>
<h2 id="FSM"><a href="#FSM" class="headerlink" title="FSM"></a>FSM</h2><p>FSM是一个system service，用来管理运行在ChCore上的多个文件系统，可以处理如下类型的请求：</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/* Client send fsm_req to FSM */</span></span><br><span class="line"><span class="class"><span class="keyword">enum</span> <span class="title">fsm_req_type</span> &#123;</span></span><br><span class="line">        FSM_REQ_UNDEFINED = <span class="number">0</span>,</span><br><span class="line"></span><br><span class="line">        FSM_REQ_PARSE_PATH,	<span class="comment">// 根据路径识别挂载点，从而识别文件系统，返回文件系统对应的service cap，其实跟procmgr的GET_SERVER_CAP差不多同一个意思</span></span><br><span class="line">        FSM_REQ_MOUNT,	<span class="comment">// 挂载某个文件系统</span></span><br><span class="line">        FSM_REQ_UMOUNT,	<span class="comment">// 卸载</span></span><br><span class="line"></span><br><span class="line">        FSM_REQ_SYNC,</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>

<blockquote>
<p>练习1：阅读 <code>user/chcore-libc/libchcore/porting/overrides/src/chcore-port/file.c</code> 的 <code>chcore_openat</code> 函数，分析 ChCore 是如何处理 <code>openat</code> 系统调用的，关注 IPC 的调用过程以及 IPC 请求的内容。</p>
<ol>
<li><p>准备：alloc一个fd、形成完整路径名</p>
<p>chcore使用的是一个全局的fd table，以无锁map形式实现，也是经典的微内核特色。</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/* Global fd desc table */</span></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">fd_desc</span> *<span class="title">fd_dic</span>[<span class="title">MAX_FD</span>] =</span> &#123;<span class="number">0</span>&#125;;</span><br></pre></td></tr></table></figure></li>
<li><p>向fsm发送一个<code>FSM_REQ_PARSE_PATH</code>请求获取mount id</p>
</li>
<li><p>向fs发送<code>FS_REQ_OPEN</code>请求</p>
</li>
</ol>
</blockquote>
<p>从<code>openat</code>的调用也可以看出FSM和FS的解耦。FSM只负责挂载/卸载和把FS的cap交给用户，获取完cap之后用户就直接访问FS service了。</p>
<h3 id="mount"><a href="#mount" class="headerlink" title="mount"></a>mount</h3><p>在看如何实现mount之前，可以先探究一下fsm的启动流程。</p>
<p>procmgr启动tmpfs和fsm两个service process：</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">void</span> <span class="title function_">boot_default_servers</span><span class="params">(<span class="type">void</span>)</span> &#123;</span><br><span class="line">        srv_path = <span class="string">&quot;/tmpfs.srv&quot;</span>;</span><br><span class="line">        proc_node = procmgr_launch_basic_server(<span class="number">1</span>, &amp;srv_path, <span class="string">&quot;tmpfs&quot;</span>, <span class="literal">true</span>, INIT_BADGE);</span><br><span class="line">        tmpfs_cap = proc_node-&gt;proc_mt_cap;</span><br><span class="line">        set_tmpfs_cap(tmpfs_cap);</span><br><span class="line"></span><br><span class="line">        srv_path = <span class="string">&quot;/fsm.srv&quot;</span>;</span><br><span class="line">        proc_node = procmgr_launch_basic_server(<span class="number">1</span>, &amp;srv_path, <span class="string">&quot;fsm&quot;</span>, <span class="literal">true</span>, INIT_BADGE);</span><br><span class="line">        fsm_server_cap = proc_node-&gt;proc_mt_cap;</span><br><span class="line">        fsm_ipc_struct-&gt;server_id = FS_MANAGER;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>然后，FSM启动后会在main函数挂载tmpfs（这也是procmgr里面那个初始化顺序的原因），挂载的大概操作是先向procmgr发请求拿tmpfs的cap，然后再初始化mount info结构体。</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">int</span> <span class="title function_">init_fsm</span><span class="params">(<span class="type">void</span>)</span> &#123;</span><br><span class="line">        <span class="comment">/* Initialize */</span></span><br><span class="line">        init_utils();</span><br><span class="line">        <span class="comment">// xiunian: firstly mount a tmpfs in boot</span></span><br><span class="line">        ret = fsm_mount_fs(<span class="string">&quot;/tmpfs.srv&quot;</span>, <span class="string">&quot;/&quot;</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>最后，FSM会打开一个跟FS的connection，用以后续跟FS service进行交互。</p>
<p>以此类推，其它FS的挂载操作其实也差不多，只不过稍显复杂一些。</p>
<p>发起挂载请求之后，会首先调用<code>mount_storage_device</code>获取FS对应的cap。而在初次调用该函数时，该函数会先读取MBR引导扇区，获知本机的磁盘分区信息，获取对应的FS类型。</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> (i = <span class="number">0</span>; i &lt; MBR_MAX_PARTS_CNT; i++) &#123;</span><br><span class="line">        pinfo = (<span class="type">partition_struct_t</span> *)(mbr + SD_PARTITION_INFO_OFFSET</span><br><span class="line">                                       + i * SD_PARTITION_INFO_SIZE);</span><br><span class="line">        dparts[i].valid = pinfo-&gt;fs_id ? <span class="literal">true</span> : <span class="literal">false</span>;</span><br><span class="line">        dparts[i].partition_index = i + <span class="number">1</span>;</span><br><span class="line">        dparts[i].mounted = <span class="literal">false</span>;</span><br><span class="line">        dparts[i].partition_lba = pinfo-&gt;lba;</span><br><span class="line">        <span class="keyword">if</span> (pinfo-&gt;fs_id == FAT32_PARTITION) &#123;</span><br><span class="line">                <span class="comment">/* FAT32 */</span></span><br><span class="line">                dparts[i].partition_type = FAT32_PARTITION;</span><br><span class="line">                dparts[i].server_id = SERVER_FAT32_FS;</span><br><span class="line">        &#125; <span class="keyword">else</span> <span class="keyword">if</span> (pinfo-&gt;fs_id == EXT4_PARTITION) &#123;</span><br><span class="line">                <span class="comment">/* EXT4 */</span></span><br><span class="line">                dparts[i].partition_type = EXT4_PARTITION;</span><br><span class="line">                dparts[i].server_id = SERVER_EXT4_FS;</span><br><span class="line">        &#125; <span class="keyword">else</span> <span class="keyword">if</span> (pinfo-&gt;fs_id == <span class="number">0</span>) &#123;</span><br><span class="line">                <span class="comment">/* do nothing */</span></span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                <span class="built_in">printf</span>(<span class="string">&quot;[WARNING] not supported fs type %x\n&quot;</span>,</span><br><span class="line">                       pinfo-&gt;fs_id);</span><br><span class="line">        &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="type">static</span> <span class="type">void</span> <span class="title function_">initialize_dparts</span><span class="params">(<span class="type">void</span>)</span></span><br><span class="line">&#123;</span><br><span class="line">        <span class="built_in">memcpy</span>(dparts[<span class="number">0</span>].device_name, <span class="string">&quot;sda1&quot;</span>, <span class="number">5</span>);</span><br><span class="line">        <span class="built_in">memcpy</span>(dparts[<span class="number">1</span>].device_name, <span class="string">&quot;sda2&quot;</span>, <span class="number">5</span>);</span><br><span class="line">        <span class="built_in">memcpy</span>(dparts[<span class="number">2</span>].device_name, <span class="string">&quot;sda3&quot;</span>, <span class="number">5</span>);</span><br><span class="line">        <span class="built_in">memcpy</span>(dparts[<span class="number">3</span>].device_name, <span class="string">&quot;sda4&quot;</span>, <span class="number">5</span>);</span><br><span class="line">        <span class="built_in">memcpy</span>(dparts[<span class="number">4</span>].device_name, <span class="string">&quot;sda5&quot;</span>, <span class="number">5</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>然后，它也依然会发送GET_SERVER_CAP请求给procmgr。procmgr会返回对应的FS service cap，如果对应的FS service尚未启动则procmgr会立刻启动它。</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">case</span> SERVER_FAT32_FS:</span><br><span class="line">        ret = boot_server(<span class="string">&quot;fat32&quot;</span>,</span><br><span class="line">                          <span class="string">&quot;/fat32.srv&quot;</span>,</span><br><span class="line">                          sys_servers + SERVER_FAT32_FS,</span><br><span class="line">                          SYSTEM_SERVER);</span><br><span class="line">        <span class="keyword">if</span> (ret == <span class="number">-1</span>) &#123;</span><br><span class="line">                <span class="keyword">goto</span> out;</span><br><span class="line">        &#125;</span><br><span class="line">        ipc_set_msg_return_cap_num(ipc_msg, <span class="number">1</span>);</span><br><span class="line">        ipc_set_msg_cap(</span><br><span class="line">                ipc_msg, <span class="number">0</span>, sys_servers[SERVER_FAT32_FS]);</span><br><span class="line">        <span class="keyword">goto</span> out;</span><br></pre></td></tr></table></figure>

<p>最后也是依然会打开一个connection用于后续交互。</p>
<p>可见mount大致流程大概就是：</p>
<ol>
<li>让procmgr启动FS service process，然后获取server cap</li>
<li>填写mount info插入链表</li>
<li>打开一个connection用于后续交互</li>
</ol>
<p>实验最主要让我们完成的还是比较简单的第三步。</p>
<p>此部分也属于是一种service间交互应用的体现吧，FS Client FSM这三者关系还算是比较交错。Client是FS、FSM的客户端，FSM是FS的客户端（发送FS_INIT等让它自助初始化），FSM也算是FS他半个爸（）</p>
<h3 id="parse-path"><a href="#parse-path" class="headerlink" title="parse path"></a>parse path</h3><p>Client端并非干脆使用server cap同FS service进行交互，而是使用mount id来表示一个FS。故而，为了实现该封装，我们就需要在Client端维护一个&lt;mount id, server cap(Client的cap)&gt;的映射和一个&lt;connection(<code>ipc_struct</code>), server cap&gt;的映射。</p>
<p>因此，我们需要在FSM端：</p>
<ol>
<li>集中存储每个Client对应的&lt;mount id, server cap(FSM的cap)&gt;映射，这对应本任务的<code>fsm_client_cap</code></li>
<li>收到parse path请求的时候，根据路径最大匹配找到对应的挂载点再找到对应的文件系统</li>
<li>根据文件系统的server cap找到mount id（调用1中接口）</li>
<li>将server cap通过IPC的cap拷贝机制copy给Client端（<code>ipc_return_with_cap</code>），然后将mount id、挂载路径写回msg中的response就行了1</li>
</ol>
<h2 id="FS-base"><a href="#FS-base" class="headerlink" title="FS_base"></a>FS_base</h2><h3 id="数据结构-1"><a href="#数据结构-1" class="headerlink" title="数据结构"></a>数据结构</h3><p>在 ChCore 中，FS_Base 是文件系统的一层 wrapper，IPC 请求首先被 FS_Base 接收，再由 FS_Base 调用实际的文件系统进行处理。</p>
<p>【其实或者说叫“基类”什么的也挺好的（）】</p>
<p>在 FS_Base wrapper 中，ChCore 实现了适用于VFS的vnode抽象，用来代表文件系统中所有的对象，包括文件、目录、链接等。它有一个private指针指向具体的各个FS的数据，比如说对于EXT4就是inode，算是多态的一种体现。 </p>
<p>ChCore 中 vnode 的定义为：</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">fs_vnode</span> &#123;</span></span><br><span class="line">        <span class="type">ino_t</span> vnode_id; <span class="comment">/* identifier */</span></span><br><span class="line">        <span class="class"><span class="keyword">struct</span> <span class="title">rb_node</span> <span class="title">node</span>;</span> <span class="comment">/* rbtree node */</span></span><br><span class="line"></span><br><span class="line">        <span class="class"><span class="keyword">enum</span> <span class="title">fs_vnode_type</span> <span class="title">type</span>;</span> <span class="comment">/* regular or directory */</span></span><br><span class="line">        <span class="type">int</span> refcnt; <span class="comment">/* reference count */</span></span><br><span class="line">        <span class="type">off_t</span> size; <span class="comment">/* file size or directory entry number */</span></span><br><span class="line">        <span class="class"><span class="keyword">struct</span> <span class="title">page_cache_entity_of_inode</span> *<span class="title">page_cache</span>;</span></span><br><span class="line">        <span class="type">cap_t</span> pmo_cap; <span class="comment">/* fmap fault is handled by this */</span></span><br><span class="line">        <span class="type">void</span> *private;</span><br><span class="line"></span><br><span class="line">        <span class="type">pthread_rwlock_t</span> rwlock; <span class="comment">/* vnode rwlock */</span></span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>

<p>再然后，为了兼容POSIX接口，外界用户态通过chcore-libc访问文件是以fd的形式，（fd是一个非负整数，它<strong>指向一个内核中的文件表项</strong>，包含了文件的状态信息和操作方法）然后每个进程的fd都集中存储在chcore-libc中。</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/* Global fd desc table */</span></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">fd_desc</span> *<span class="title">fd_dic</span>[<span class="title">MAX_FD</span>] =</span> &#123;<span class="number">0</span>&#125;;	<span class="comment">// userspace libc data, per-process</span></span><br></pre></td></tr></table></figure>

<p>而在FS内部，使用了一个<code>server_entry</code>结构体，用来作为POSIX中fd指向的那个文件表项，其表索引为fid。</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// per-fd</span></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">server_entry</span> &#123;</span></span><br><span class="line">        <span class="comment">/* `flags` and `offset` is assigned to each fd */</span></span><br><span class="line">        <span class="type">int</span> flags;</span><br><span class="line">        <span class="type">off_t</span> offset;</span><br><span class="line">        <span class="type">int</span> refcnt;	<span class="comment">// used for dup2</span></span><br><span class="line">        <span class="comment">/*</span></span><br><span class="line"><span class="comment">         * Different FS may use different struct to store path,</span></span><br><span class="line"><span class="comment">         * normally `char*`</span></span><br><span class="line"><span class="comment">         */</span></span><br><span class="line">        <span class="type">void</span> *path;</span><br><span class="line">        <span class="comment">/* Entry lock */</span></span><br><span class="line">        <span class="type">pthread_mutex_t</span> lock;</span><br><span class="line">        <span class="comment">/* Each vnode is binding with a disk inode */</span></span><br><span class="line">        <span class="class"><span class="keyword">struct</span> <span class="title">fs_vnode</span> *<span class="title">vnode</span>;</span></span><br><span class="line">&#125;;</span><br><span class="line"><span class="keyword">extern</span> <span class="class"><span class="keyword">struct</span> <span class="title">server_entry</span> *<span class="title">server_entrys</span>[<span class="title">MAX_SERVER_ENTRY_NUM</span>];</span></span><br></pre></td></tr></table></figure>

<p>因此，FS_Base 的 IPC handler 在处理 IPC 请求时，会先把 IPC 消息中包含的文件 fd 转换为 fid，所以我们文件系统内部需要维护一个<code>(client badge, fd) -&gt; (fid)</code>的映射：</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/* (client_badge, fd) -&gt; fid(server_entry) */</span></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">server_entry_node</span> &#123;</span></span><br><span class="line">        <span class="type">badge_t</span> client_badge;</span><br><span class="line">        <span class="type">int</span> fd_to_fid[MAX_SERVER_ENTRY_PER_CLIENT];</span><br><span class="line"></span><br><span class="line">        <span class="class"><span class="keyword">struct</span> <span class="title">list_head</span> <span class="title">node</span>;</span></span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="keyword">extern</span> <span class="class"><span class="keyword">struct</span> <span class="title">list_head</span> <span class="title">server_entry_mapping</span>;</span></span><br><span class="line"><span class="keyword">extern</span> <span class="type">pthread_spinlock_t</span> server_entry_mapping_lock;</span><br></pre></td></tr></table></figure>

<h3 id="fs-wrapper-ops"><a href="#fs-wrapper-ops" class="headerlink" title="fs_wrapper_ops"></a>fs_wrapper_ops</h3><p>当我们拥有了文件表项和VNode抽象后，我们便可以实现真正的文件系统操作了。</p>
<p>我们可以将 FS_Base 以及 FS_Wrapper 的所有逻辑看成一个 VFS 的通用接口，其暴露出的接口定义为 <code>strcut fs_server_ops</code>。FS只需要实现该结构体的操作即可，FS wrapper会调用它。</p>
<p>我们可以来看看tmpfs具体是什么样的架构。</p>
<p>首先tmpfs以<code>fs_server_dispatch</code>为handler注册为了一个IPC server：</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">info(<span class="string">&quot;register server value = %u\n&quot;</span>,</span><br><span class="line">     ipc_register_server_with_destructor(fs_server_dispatch,</span><br><span class="line">                                         DEFAULT_CLIENT_REGISTER_HANDLER,</span><br><span class="line">                                         fs_server_destructor));</span><br></pre></td></tr></table></figure>

<p><code>fs_server_dispatch</code>定义在FS wrapper中，是对所有FS通用的一个server handler。它会先把fd转化为fid，然后根据请求类型调用相应处理函数：</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">DEFINE_SERVER_HANDLER(fs_server_dispatch) &#123;</span><br><span class="line">        <span class="comment">// Now fr-&gt;fd stores the `Client Side FD Index&#x27;</span></span><br><span class="line">        ret = translate_fd_to_fid(client_badge, fr);</span><br><span class="line">        <span class="comment">/*</span></span><br><span class="line"><span class="comment">         * FS Server Requests Handlers</span></span><br><span class="line"><span class="comment">         */</span></span><br><span class="line">        <span class="keyword">switch</span> (fr-&gt;req) &#123;</span><br><span class="line">        <span class="keyword">case</span> FS_REQ_MOUNT:</span><br><span class="line">                ret = fs_wrapper_mount(ipc_msg, fr);</span><br><span class="line">                <span class="keyword">break</span>;</span><br><span class="line">        <span class="keyword">case</span> FS_REQ_OPEN:</span><br><span class="line">                ret = fs_wrapper_open(client_badge, ipc_msg, fr);</span><br><span class="line">                <span class="keyword">break</span>;</span><br><span class="line">        <span class="keyword">case</span> FS_REQ_READ:</span><br><span class="line">                ret = fs_wrapper_read(ipc_msg, fr);</span><br><span class="line">                <span class="keyword">break</span>;</span><br><span class="line">        ...</span><br></pre></td></tr></table></figure>

<p>以<code>mount</code>为例，可以看到它最终会调用server ops的函数：</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">int</span> <span class="title function_">fs_wrapper_mount</span><span class="params">(<span class="type">ipc_msg_t</span> *ipc_msg, <span class="keyword">struct</span> fs_request *fr)</span> &#123;</span><br><span class="line">        ret = server_ops.mount(ipc_msg, fr);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>也即tmpfs定义的具体server ops：</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">fs_server_ops</span> <span class="title">server_ops</span> =</span> &#123;</span><br><span class="line">        <span class="comment">/* Unimplemented */</span></span><br><span class="line">        .mount = default_server_operation,</span><br><span class="line">        .umount = default_server_operation,</span><br><span class="line">        <span class="comment">/* File Operations */</span></span><br><span class="line">        .creat = tmpfs_creat,</span><br><span class="line">        .open = tmpfs_open,</span><br><span class="line">        .write = tmpfs_write,</span><br><span class="line">		...</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>

<p>对于本 Lab 你只需要实现最基本的 Posix 文件操作即可，即 Open，Close，Read, Write 以及 LSeek 操作。具体的没啥好说的，就是常规的FS，体力活。</p>
<h2 id="其它"><a href="#其它" class="headerlink" title="其它"></a>其它</h2><p>TODO  之后有时间可以研究一下file page fault和cache的代码是怎么写的。</p>

        </div>

        
        <section class="post-tags">
            <div>
                <span>Tag(s):</span>
                <span class="tag">
                    
                </span>
            </div>
            <div>
                <a href="javascript:window.history.back();">back</a>
                <span>· </span>
                <a href="/">home</a>
            </div>
        </section>
        <section class="post-nav">
            
                <a class="prev" rel="prev" href="/2024/08/11/chcore/">ChCore</a>
            
            
            <a class="next" rel="next" href="/2024/07/06/thinks/">杂记</a>
            
        </section>


    </article>
</div>

            </div>
            <footer id="footer" class="footer">
    <div class="copyright">
        <span>© 修年 | Powered by <a href="https://hexo.io" target="_blank">Hexo</a> & <a href="https://github.com/Siricee/hexo-theme-Chic" target="_blank">Chic</a></span>
    </div>
</footer>

    </div>
</body>

</html>